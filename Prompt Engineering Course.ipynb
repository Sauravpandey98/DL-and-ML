{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48ad528c",
   "metadata": {},
   "source": [
    "# This tutorial is based on Deeplearning prompt engineering crash course\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f514452",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "openai.api_key  = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc6a955",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0, # this is the degree of randomness of the model's output\n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]\n",
    "\n",
    "\n",
    "def get_completion_from_messages(messages, model=\"gpt-3.5-turbo\", temperature=0):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature, # this is the degree of randomness of the model's output\n",
    "    )\n",
    "#     print(str(response.choices[0].message))\n",
    "    return response.choices[0].message[\"content\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca559fe",
   "metadata": {},
   "source": [
    "# Part 1: Important Guidelines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574c42f4",
   "metadata": {},
   "source": [
    "## First Principle\n",
    "\n",
    "First prinnciple of writing good prompts is to write is clear and precise.It does not matter how long the prompt is if it able to clearly specify the task.Following tactics can be followed to write such prompts.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e55c1d",
   "metadata": {},
   "source": [
    "### Use Delimeter and punctuation to separate different sections of text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf1442e",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = f\"\"\"\n",
    "You should express what you want a model to do by \\ \n",
    "providing instructions that are as clear and \\ \n",
    "specific as you can possibly make them. \\ \n",
    "This will guide the model towards the desired output, \\ \n",
    "and reduce the chances of receiving irrelevant \\ \n",
    "or incorrect responses. Don't confuse writing a \\ \n",
    "clear prompt with writing a short prompt. \\ \n",
    "In many cases, longer prompts provide more clarity \\ \n",
    "and context for the model, which can lead to \\ \n",
    "more detailed and relevant outputs.\n",
    "\"\"\"\n",
    "prompt = f\"\"\"\n",
    "Summarize the text delimited by triple backticks \\ \n",
    "into a single sentence.\n",
    "```{text}```\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)\n",
    "\n",
    "#In this example I tried by removing some delimeters and making the prompt less structured.\n",
    "#But it does not seemed to have major effect.But still it can be assumed \n",
    "#that better answer will be given for the prompt which follows this tactics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be56ef1d",
   "metadata": {},
   "source": [
    "### this tactic is development based.As we can ask the ChatGPT to also return the output in particular format.This feature provides us ease of processing a standard format output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b94157",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "Generate a list of three made-up book titles along \\ \n",
    "with their authors and genres. \n",
    "Provide them in JSON format with the following keys: \n",
    "book_id, title, author, genre.\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02558639",
   "metadata": {},
   "source": [
    "### We can also ask the ChatGPT to provide condition based answers.We can multiple conditions and thier responses in the promp.One use of this type of feature is responding the user on the basis of emotion predicted in the input text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24084c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_2 =\n",
    "f\"\"\"\n",
    "Saurav is smart and intelligent.\n",
    "\"\"\" \n",
    "\n",
    "prompt =\n",
    "f\"\"\"\n",
    "You will be provided with text delimited by triple backticks. \n",
    "\n",
    "If the text contains only good things about Saurav.Then write the following response: \\\n",
    "\\\"Thanks,You are good guy. \\\"\n",
    "\n",
    "-------------------------------------\n",
    "If the text indicate that the writer is jealous from Saurav.Then write the following response: \\\n",
    "\\\"It seems that you are jealous of Saurav. \\\"\n",
    "\n",
    "--------------------------------------\n",
    "If the text contains at least one thing bad about Saurav and it does not indicate jealousy.Then write the following response: \\\n",
    "\\\"You are `emotion` of Saurav.\\\".Here `emotion' is a place holder for the emotion depicted in the text.\n",
    "\n",
    "---------------------------------------\n",
    "The text is: \\\n",
    "```{text_2}```\n",
    "\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(\"Completion for Text 2:\")\n",
    "print(response)\n",
    "\n",
    "#it was a funny way of checking this feature.* - *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc72f0c8",
   "metadata": {},
   "source": [
    "### Few Shot Prompting.This feature is based on making the model understand the output structure and then reply to the input.There are some use cases that I can think of this feature:\n",
    "\n",
    "* Solving Puzzles\n",
    "* Restructuring Structured Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4710999",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "You will be given some example conatining the question and thier respective answer. \\\n",
    "Through these examples, you need to understand the reason behind each answer. \\\n",
    "Each answer will be based upon same reasoning. \\\n",
    "Your task is to give the answer of a question using the same reasoning that was appliied while solving the example questions.\n",
    "\n",
    " ---------------------\n",
    " Examples:\n",
    " 1. Question: Apple+Mango\n",
    "    Answer: Orange\n",
    " 2. Question: Blueberry+Pineberry\n",
    "    Answer: Skyblue\n",
    " 3. Question: Blueberry+Mango\n",
    "    Answer:   Green\n",
    "\n",
    " Question to be answered:\n",
    " Question: Apple+Green Grapes\n",
    " Answer: ?\n",
    " \n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)\n",
    "\n",
    "##In this example model is not able to understand the reasoning clearly.The answer given by Model is \"Red\".But the actual answer is orange."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ef3191",
   "metadata": {},
   "source": [
    "## Principal 2: Give the model time to think"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c676c98",
   "metadata": {},
   "source": [
    "### In case if the problem is little complex to solve,then we can change the prompt using following tactics.These tactics increase the amount of computation but also helps in increasing accuracy:\n",
    "\n",
    "* Specify the steps that model should follow to get the response\n",
    "\n",
    "* Ask the model to work out its own solution first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433bdb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "Determine if the student's solution is correct or not.\n",
    "\n",
    "Question:\n",
    "I'm building a solar power installation and I need \\\n",
    " help working out the financials. \n",
    "- Land costs $100 / square foot\n",
    "- I can buy solar panels for $250 / square foot\n",
    "- I negotiated a contract for maintenance that will cost \\ \n",
    "me a flat $100k per year, and an additional $10 / square \\\n",
    "foot\n",
    "What is the total cost for the first year of operations \n",
    "as a function of the number of square feet.\n",
    "\n",
    "Student's Solution:\n",
    "Let x be the size of the installation in square feet.\n",
    "Costs:\n",
    "1. Land cost: 100x\n",
    "2. Solar panel cost: 250x\n",
    "3. Maintenance cost: 100,000 + 100x\n",
    "Total cost: 100x + 250x + 100,000 + 100x = 450x + 100,000\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)\n",
    "\n",
    "#the answer in this case was wrong,hence we will follow the second point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a670aa88",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "Your task is to determine if the student's solution \\\n",
    "is correct or not.\n",
    "To solve the problem do the following:\n",
    "- First, work out your own solution to the problem. \n",
    "- Then compare your solution to the student's solution \\ \n",
    "and evaluate if the student's solution is correct or not. \n",
    "Don't decide if the student's solution is correct until \n",
    "you have done the problem yourself.\n",
    "\n",
    "Use the following format:\n",
    "Question:\n",
    "```\n",
    "question here\n",
    "```\n",
    "Student's solution:\n",
    "```\n",
    "student's solution here\n",
    "```\n",
    "Actual solution:\n",
    "```\n",
    "steps to work out the solution and your solution here\n",
    "```\n",
    "Is the student's solution the same as actual solution \\\n",
    "just calculated:\n",
    "```\n",
    "yes or no\n",
    "```\n",
    "Student grade:\n",
    "```\n",
    "correct or incorrect\n",
    "```\n",
    "\n",
    "Question:\n",
    "```\n",
    "I'm building a solar power installation and I need help \\\n",
    "working out the financials. \n",
    "- Land costs $100 / square foot\n",
    "- I can buy solar panels for $250 / square foot\n",
    "- I negotiated a contract for maintenance that will cost \\\n",
    "me a flat $100k per year, and an additional $10 / square \\\n",
    "foot\n",
    "What is the total cost for the first year of operations \\\n",
    "as a function of the number of square feet.\n",
    "``` \n",
    "Student's solution:\n",
    "```\n",
    "Let x be the size of the installation in square feet.\n",
    "Costs:\n",
    "1. Land cost: 100x\n",
    "2. Solar panel cost: 250x\n",
    "3. Maintenance cost: 100,000 + 100x\n",
    "Total cost: 100x + 250x + 100,000 + 100x = 450x + 100,000\n",
    "```\n",
    "Actual solution:\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)\n",
    "\n",
    "#in this case answer came out be correct.Let's try this method in our own problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c706c48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "##lets try some points from above prompt\n",
    "\n",
    "prompt = f\"\"\"\n",
    "\n",
    "Your task is to give the solution of the question:\n",
    "To solve the problem do the following:\n",
    "- First, work out your own solution to the questions whoose answer is given\n",
    "- Then compare your solutions to the given answers\n",
    "and evaluate if your solutions is same as given answers. \n",
    "Don't decide on the solution of unanswered question until all the answers of the questions whoose answer is given \\\n",
    "matched to your answers.\n",
    "\n",
    "-----------------------\n",
    "Use the following format:\n",
    "Question:\n",
    "```\n",
    "question here\n",
    "```\n",
    "Answer:\n",
    "```\n",
    "answer here\n",
    "```\n",
    "\n",
    " ---------------------\n",
    "Question\n",
    "```\n",
    "You need to give correct answer of the question where answer is written as `?`.All the answer is based on some specific reasoning.\\\n",
    "You can deduce that reasoning from the questions for which answers are available.And aplly same reasoning to the other questions that needed to be answered.\n",
    " 1. Question: Apple+Mango\n",
    "    Answer: Orange\n",
    " 2. Question: Blueberry+Pineberry\n",
    "    Answer: Skyblue\n",
    " 3. Question: Blueberry+Mango\n",
    "    Answer:   Green\n",
    " 4.  Question: Apple+Green Grapes\n",
    "     Answer: ?\n",
    "```\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)\n",
    "\n",
    "##Here also model failed.Hmm,do now know where the problem is.Might try another variation later."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9356f7",
   "metadata": {},
   "source": [
    "## Model Hallucination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7294c093",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sometime the model can create information that is not actually present\n",
    "prompt = f\"\"\"\n",
    "Tell me about AeroGlide UltraSlim Smart Toothbrush by Boie\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)\n",
    "\n",
    "#here Boie is real but there is not product like AeroGlide UltraSlim Samrt Toothbrush"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df4f9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#there is one way to reduce this problem,\n",
    "#is to ask the model to find the relevant information and then answer based on that relevant information\n",
    "prompt = f\"\"\"\n",
    "\n",
    "```\n",
    "Tell me about AeroGlide UltraSlim Smart Toothbrush by Boie.\n",
    "```\n",
    "\n",
    "While answering this question firstly find relevant information.\\\n",
    "Then answer the question based on the relevant information\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)\n",
    "\n",
    "#here the answer comes out to be correct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b264afc",
   "metadata": {},
   "source": [
    "## Let's explore the summary building capability of ChatGPT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e22a6c",
   "metadata": {},
   "source": [
    "### let's build a review reader for a ecommerce site that can have following features:\n",
    "* It should be able to summarise the review based on the following context filters:\n",
    "    * Product\n",
    "    * Pricing\n",
    "    * Shipping\n",
    "* It should be able to summarise the review to the number of words inputted by user.\n",
    "* In the summary it should be able to put more focus on a particular context.The context can be the following and will be inputted by user\n",
    "    * Product\n",
    "    * Pricing\n",
    "    * Shipping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1152f9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define some custom data types\n",
    "from enum import Enum\n",
    "from typing import Any\n",
    "\n",
    "# for context\n",
    "class Context(Enum):\n",
    "    PRODUCT=\"PRODUCT\"\n",
    "    PRICING=\"PRICING\"\n",
    "    SHIPPING=\"SHIPPING\"\n",
    "    \n",
    "class SummaryType(Enum):\n",
    "    CONTEXTRELEVANT=\"RELEVANT TO CONTEXT\"\n",
    "    FULLSUMMARY=\"FULL SUMMARY\"\n",
    "\n",
    "# a data type that is used to limiting the number of words \n",
    "class LimitNumber:\n",
    "    def __init__(self, value):\n",
    "        if not isinstance(value, int) or value <= 0:\n",
    "            raise ValueError(\"Value must be a positive integer.\")\n",
    "        self.value = value\n",
    "    \n",
    "        \n",
    "class ContextReviewPrompts():\n",
    "    \n",
    "    PRODUCT_REVIEW_PROMPT=\"\"\"to give feedback to the \\\n",
    "    product deparmtment, responsible for overseeing merchandise in online \\\n",
    "    business operations and strategies.  \\\n",
    "\n",
    "    Summarize the review below, delimited by triple \\\n",
    "    backticks,by focusing on any aspects \\\n",
    "    that are relevant to the product quality.\"\"\"\n",
    "    \n",
    "    SHIPPING_REVIEW_PROMPT=\"\"\"to give feedback to the \\\n",
    "    shipping deparmtment. \\\n",
    "\n",
    "    Summarize the review below, delimited by triple \\\n",
    "    backticks, by focusing on any aspects \\\n",
    "    that are relevant to the shipping and delivery\"\"\"\n",
    "    \n",
    "    PRICING_REVIEW_PROMPT=\"\"\"\n",
    "    to give feedback to the \\\n",
    "    pricing deparmtment, responsible for determining the \\\n",
    "    price of the product.  \\\n",
    "\n",
    "    Summarize the review below, delimited by triple \\\n",
    "    backticks, by focusing on any aspects \\\n",
    "    that are relevant to the price and perceived value.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __call__(self, context: Context) -> Any:\n",
    "        \n",
    "        if context == Context.PRODUCT:\n",
    "            return self.PRODUCT_REVIEW_PROMPT\n",
    "        \n",
    "        if context == Context.PRICING:\n",
    "            return self.PRICING_REVIEW_PROMPT\n",
    "        \n",
    "        if context == Context.SHIPPING:\n",
    "            return self.SHIPPING_REVIEW_PROMPT  \n",
    "        \n",
    "class SummarySpecificPrompts():\n",
    "    \n",
    "    CONTEXTRELEVANT=\"to extract relevant information from\"\n",
    "    FULLSUMMARY=\"to generate a short summary from\"\n",
    "    \n",
    "    def __call__(self,summary_type: SummaryType):\n",
    "        \n",
    "        if summary_type == SummaryType.FULLSUMMARY:\n",
    "            return self.FULLSUMMARY\n",
    "        \n",
    "        if summary_type == SummaryType.CONTEXTRELEVANT:\n",
    "            return self.CONTEXTRELEVANT\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ea62521",
   "metadata": {},
   "outputs": [],
   "source": [
    "#utils functions;\n",
    "\n",
    "def get_context_prompt(context: Context=Context.PRODUCT):\n",
    "    \n",
    "    context_based_prompt=ContextReviewPrompts()\n",
    "    return context_based_prompt(context = context)\n",
    "\n",
    "def get_summary_type_prompt(summary_type: SummaryType = SummaryType.FULLSUMMARY):\n",
    "    summary_type_prompts=SummarySpecificPrompts()\n",
    "    return summary_type_prompts(summary_type = summary_type)\n",
    "\n",
    "def get_final_prompt(review,context: Context = Context.PRODUCT, summary_type : SummaryType = SummaryType.FULLSUMMARY, \\\n",
    "                    total_words : LimitNumber = None ):\n",
    "    \n",
    "    summary_prompt=get_summary_type_prompt(summary_type)\n",
    "    context_prompt=get_context_prompt(context)\n",
    "    \n",
    "    prompt= f\"\"\"Your task is {summary_prompt} a product \\\n",
    "    review from an ecommerce site {context_prompt} \\\n",
    "\n",
    "    Review: ```{review}```\n",
    "    \"\"\"\n",
    "    \n",
    "    if total_words:\n",
    "        limit_to_words=total_words.value\n",
    "        prompt=f\"\"\"Your task is {summary_prompt} from a product \\\n",
    "        review from an ecommerce site {context_prompt} \\\n",
    "        \n",
    "        Limit to {limit_to_words} words. \\\n",
    "        \n",
    "        Review: ```{review}``` \n",
    "        \"\"\"\n",
    "        \n",
    "    return prompt\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b559f94a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your task is to generate a short summary of a product         review from an ecommerce site to give feedback to the     product deparmtment, responsible for overseeing merchandise in online     business operations and strategies.  \\n    Summarize the review below, delimited by triple     backticks,by focusing on any aspects     that are relevant to the product quality.         \\n        Limit to 10 words.         \\n        Review: `````` \\n        '"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review= \"\"\"\n",
    "Got this panda plush toy for my daughter's birthday, \\\n",
    "who loves it and takes it everywhere. It's soft and \\ \n",
    "super cute, and its face has a friendly look. It's \\ \n",
    "a bit small for what I paid though. I think there \\ \n",
    "might be other options that are bigger for the \\ \n",
    "same price. It arrived a day earlier than expected, \\ \n",
    "so I got to play with it myself before I gave it \\ \n",
    "to her.\n",
    "\"\"\"\n",
    "context=\"SHIPPING\"\n",
    "summary_type=\"FULLSUMMARY\"\n",
    "limit_to_words=LimitNumber(10)\n",
    "# limit_to_words=None\n",
    "\n",
    "prompt=get_final_prompt(review,context = Context[context], summary_type = SummaryType[summary_type],total_words=limit_to_words)\n",
    "\n",
    "get_completion(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2abf39",
   "metadata": {},
   "source": [
    "## We can also do following ML based tasks with ChatGPT:\n",
    "* Sentiment Analysis\n",
    "* Emotion Prediction\n",
    "* Topic Prediction\n",
    "* Label Extraction (Extraction particular labels like company name,product name from text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a7f71909",
   "metadata": {},
   "outputs": [],
   "source": [
    "lamp_review = \"\"\"\n",
    "Needed a nice lamp for my bedroom, and this one had \\\n",
    "additional storage and not too high of a price point. \\\n",
    "Got it fast. But the string was not working.Asked for replacement.Got the new one in three days.\n",
    "The new one also had an issue in thier lamp.Thier product qualtity is too bad.The customer service is also not good.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d79f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "Identify the following items from the review text: \n",
    "- Sentiment (positive or negative)\n",
    "- Is the reviewer expressing anger? (true or false)\n",
    "- Item purchased by reviewer\n",
    "- Company that made the item\n",
    "\n",
    "The review is delimited with triple backticks. \\\n",
    "Format your response as a JSON object with \\\n",
    "\"Sentiment\", \"Anger\", \"Item\" and \"Brand\" as the keys.\n",
    "If the information isn't present, use \"unknown\" \\\n",
    "as the value.\n",
    "Make your response as short as possible.\n",
    "Format the Anger value as a boolean.\n",
    "\n",
    "Review text: '''{lamp_review}'''\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c504cc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we can also ask the model for confidence value of each emotion prediction\n",
    "prompt = f\"\"\"\n",
    "Identify a list of emotions that the writer of the \\\n",
    "following review is expressing. Include no more than \\\n",
    "five items in the list.\n",
    "\n",
    "Also for which emotion, give the confidence value indicating your confidence regarding presence of that particular emotion.\n",
    "\n",
    "Please give answer in following format\n",
    "```\n",
    "Emotions: List of emotions here\n",
    "Confidence: List of confidence value correspoing to each emotion present in Emotions.\n",
    "```\n",
    "Confidence value should be between 0 and 1.\n",
    "\n",
    "Review text: '''{lamp_review}'''\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17ca85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict topics of a text\n",
    "story = \"\"\"\n",
    "In a recent survey conducted by the government, \n",
    "public sector employees were asked to rate their level \n",
    "of satisfaction with the department they work at. \n",
    "The results revealed that NASA was the most popular \n",
    "department with a satisfaction rating of 95%.\n",
    "\n",
    "One NASA employee, John Smith, commented on the findings, \n",
    "stating, \"I'm not surprised that NASA came out on top. \n",
    "It's a great place to work with amazing people and \n",
    "incredible opportunities. I'm proud to be a part of \n",
    "such an innovative organization.\"\n",
    "\n",
    "The results were also welcomed by NASA's management team, \n",
    "with Director Tom Johnson stating, \"We are thrilled to \n",
    "hear that our employees are satisfied with their work at NASA. \n",
    "We have a talented and dedicated team who work tirelessly \n",
    "to achieve our goals, and it's fantastic to see that their \n",
    "hard work is paying off.\"\n",
    "\n",
    "The survey also revealed that the \n",
    "Social Security Administration had the lowest satisfaction \n",
    "rating, with only 45% of employees indicating they were \n",
    "satisfied with their job. The government has pledged to \n",
    "address the concerns raised by employees in the survey and \n",
    "work towards improving job satisfaction across all departments.\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Determine five topics that are being discussed in the \\\n",
    "following text, which is delimited by triple backticks.\n",
    "\n",
    "Make each item one or two words long. \n",
    "\n",
    "Format your response as a list of items separated by commas.\n",
    "\n",
    "Text sample: '''{story}'''\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0495ff3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_list = [\n",
    "    \"nasa\", \"local government\", \"engineering\", \n",
    "    \"employee satisfaction\", \"federal government\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dfe1f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "Determine whether each item in the following list of \\\n",
    "topics is a topic in the text below, which\n",
    "is delimited with triple backticks.\n",
    "\n",
    "Give your answer as list with 0 or 1 for each topic.\\\n",
    "\n",
    "List of topics: {\", \".join(topic_list)}\n",
    "\n",
    "Text sample: '''{story}'''\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b240a97",
   "metadata": {},
   "source": [
    "### Some Important Findings\n",
    "* Let suppose in a text that has positive sentiment,models was asked to give the negative emotions,then model will inlcude some postive emotions in the list.\n",
    "* Hence in this case we should follow the principal of giving the model time to think.\n",
    "* We can ask the model to follow following steps:\n",
    "    * Predict the Sentiment\n",
    "    * If positive,list down the positive emotions\n",
    "    * If negative,do nothing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c0b9250",
   "metadata": {},
   "source": [
    "## Transforming capapbilities of ChatGPT\n",
    "\n",
    "We can use ChatGPT to do the following things:\n",
    "* Translation from one lanuage to another lanuage.\n",
    "* Translation or conversion of a text into different tunes.For example converting a piece of text into formal or informal tunes.\n",
    "* It can be used as a Universal Translator!!!\n",
    "* It can be used to grammar correction.\n",
    "* Convert one format of piece of text to another format.For example JSON to HTML or python to JAVA.\n",
    "\n",
    "Let's explore each one of the example one by one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204a682d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# translation\n",
    "prompt = f\"\"\"\n",
    "Translate the following spanish text to Sanskrit: \\ \n",
    "```Hola, me gustaría ordenar una licuadora.```\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)\n",
    "\n",
    "#NOTE: \n",
    "    #   If instead of spanish text,I use only the text in the prompt,then model results quanlity decreases.\n",
    "    # We can also ask the model to write answer in multiple tunes like formal or informal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d083f79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Universal Translator\n",
    "user_messages = [\n",
    "  \"La performance du système est plus lente que d'habitude.\",  # System performance is slower than normal         \n",
    "  \"Mi monitor tiene píxeles que no se iluminan.\",              # My monitor has pixels that are not lighting\n",
    "  \"Il mio mouse non funziona\",                                 # My mouse is not working\n",
    "  \"Mój klawisz Ctrl jest zepsuty\",                             # My keyboard has a broken control key\n",
    "  \"我的屏幕在闪烁\"                                               # My screen is flashing\n",
    "] \n",
    "\n",
    "for issue in user_messages:\n",
    "    prompt = f\"Tell me what language this is: ```{issue}```\"\n",
    "    lang = get_completion(prompt)\n",
    "    print(f\"Original message ({lang}): {issue}\")\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    Translate the following  text to English \\\n",
    "    and Korean: ```{issue}```\n",
    "    \"\"\"\n",
    "    response = get_completion(prompt)\n",
    "    print(response, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854efda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tone transformation\n",
    "prompt = f\"\"\"\n",
    "Translate the following from slang to a business letter: \n",
    "'Dude, This is Joe, check out this spec on this standing lamp.'\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2968dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the type (json to HTML).\n",
    "data_json = { \"resturant employees\" :[ \n",
    "    {\"name\":\"Shyam\", \"email\":\"shyamjaiswal@gmail.com\"},\n",
    "    {\"name\":\"Bob\", \"email\":\"bob32@gmail.com\"},\n",
    "    {\"name\":\"Jai\", \"email\":\"jai87@gmail.com\"}\n",
    "]}\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Translate the following python dictionary from JSON to an HTML \\\n",
    "table: {data_json}\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)\n",
    "\n",
    "#display the html response\n",
    "from IPython.display import display, Markdown, Latex, HTML, JSON\n",
    "display(HTML(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad0c3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#spell check or grammer check\n",
    "text = [ \n",
    "  \"The girl with the black and white puppies have a ball.\",  # The girl has a ball.\n",
    "  \"Yolanda has her notebook.\", # ok\n",
    "  \"Its going to be a long day. Does the car need it’s oil changed?\",  # Homonyms\n",
    "  \"Their goes my freedom. There going to bring they’re suitcases.\",  # Homonyms\n",
    "  \"Your going to need you’re notebook.\",  # Homonyms\n",
    "  \"That medicine effects my ability to sleep. Have you heard of the butterfly affect?\", # Homonyms\n",
    "  \"This phrase is to cherck chatGPT for speling abilitty\"  # spelling\n",
    "]\n",
    "for t in text:\n",
    "    prompt = f\"\"\"Proofread and correct the following text\n",
    "    and rewrite the corrected version. If you don't find\n",
    "    any errors, just say \"No errors found\". Don't use \n",
    "    any punctuation around the text:\n",
    "    ```{t}```\"\"\"\n",
    "    response = get_completion(prompt)\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705f7936",
   "metadata": {},
   "source": [
    "## Expansion capability of model\n",
    "\n",
    "We can ask model to use a piece of text to generate something else.For example,we can generate an AI generated reply mail from a user review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4a5d194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# given the sentiment from the lesson on \"inferring\",\n",
    "# and the original customer message, customize the email\n",
    "sentiment = \"negative\"\n",
    "\n",
    "# review for a blender\n",
    "review = f\"\"\"\n",
    "So, they still had the 17 piece system on seasonal \\\n",
    "sale for around $49 in the month of November, about \\\n",
    "half off, but for some reason (call it price gouging) \\\n",
    "around the second week of December the prices all went \\\n",
    "up to about anywhere from between $70-$89 for the same \\\n",
    "system. And the 11 piece system went up around $10 or \\\n",
    "so in price also from the earlier sale price of $29. \\\n",
    "So it looks okay, but if you look at the base, the part \\\n",
    "where the blade locks into place doesn’t look as good \\\n",
    "as in previous editions from a few years ago, but I \\\n",
    "plan to be very gentle with it (example, I crush \\\n",
    "very hard items like beans, ice, rice, etc. in the \\ \n",
    "blender first then pulverize them in the serving size \\\n",
    "I want in the blender then switch to the whipping \\\n",
    "blade for a finer flour, and use the cross cutting blade \\\n",
    "first when making smoothies, then use the flat blade \\\n",
    "if I need them finer/less pulpy). Special tip when making \\\n",
    "smoothies, finely cut and freeze the fruits and \\\n",
    "vegetables (if using spinach-lightly stew soften the \\ \n",
    "spinach then freeze until ready for use-and if making \\\n",
    "sorbet, use a small to medium sized food processor) \\ \n",
    "that you plan to use that way you can avoid adding so \\\n",
    "much ice if at all-when making your smoothie. \\\n",
    "After about a year, the motor was making a funny noise. \\\n",
    "I called customer service but the warranty expired \\\n",
    "already, so I had to buy another one. FYI: The overall \\\n",
    "quality has gone done in these types of products, so \\\n",
    "they are kind of counting on brand recognition and \\\n",
    "consumer loyalty to maintain sales. Got it in about \\\n",
    "two days.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99985c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "You are a customer service AI assistant.\n",
    "Your task is to send an email reply to a valued customer.\n",
    "Given the customer email delimited by ```, \\\n",
    "Generate a reply to thank the customer for their review.\n",
    "If the sentiment is positive or neutral, thank them for \\\n",
    "their review.\n",
    "If the sentiment is negative, apologize and suggest that \\\n",
    "they can reach out to customer service. \n",
    "Make sure to use specific details from the review.\n",
    "Write in a concise and professional tone.\n",
    "Sign the email as `AI customer agent`.\n",
    "Customer review: ```{review}```\n",
    "Review sentiment: {sentiment}\n",
    "\"\"\"\n",
    "response = get_completion(prompt,temperatur=0.7)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bfac1a8",
   "metadata": {},
   "source": [
    "### Temperature parameter\n",
    "Temperatur parameter is used to introduce randomness in the response of model.If temperature is zero,then model always picks the next word which has best confidence.For example,After \"My Best Food is\",it will always picks up pizza as pizza has the highest probability if the temperature is zero.But if temperature is not zero,then it might also pick up other words like tacos,burger etc.This randomness increases as we increase the temperature.So here are following tips for using the temperature parameter.\n",
    "\n",
    "* If we want the output to be predictable.For example during transformation use cases,we can keep the temperature to be zero.\n",
    "* If we want the output to be more creative and random,for example in chatbot or a poem generation,we can should increase the temperature.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0138537b",
   "metadata": {},
   "source": [
    "## ChatBOT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e0aba9",
   "metadata": {},
   "source": [
    "### Let firstly understand how does the model works internally while using the ChatGPT web interface.\n",
    "\n",
    "So, in general ChatGPT is a chat based model where a user give a input to a assistant and assistant replies to that input.\n",
    "\n",
    "                Assistant\n",
    "                 ↑  ↓\n",
    "                 User\n",
    "\n",
    "Every new call to the model is a new conversation,so to let the model gives answers based on previous conversation,we need to give the previous conversation along with the current query as an input to the model.The previous conversation is called \"context\" for the model.\n",
    "\n",
    "Now before starting a conversation with the model,we can also specify how does the model should behave during conversation.So for a chatbot,there are generaly three type of prompts in a conversation.\n",
    "\n",
    "1. system: specifies how does the models should behaves.For example,we can ask the model to be a friendly assistant and answer like Shakespeare.\n",
    "\n",
    "2. assistant : The message by the model.\n",
    "\n",
    "3. user : The message by the user.\n",
    "\n",
    "                   System \n",
    "                      ↓ (only once in a conversion)\n",
    "                   Assistant\n",
    "                    ↑  ↓  (repeated conversation)\n",
    "                    User              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f954465",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets try this practically\n",
    "messages =  [  \n",
    "{'role':'system', 'content':'You are an assistant that speaks like Shakespeare.'},  #sets the assistant behaviour in this conversation  \n",
    "{'role':'user', 'content':'tell me a joke'},   \n",
    "{'role':'assistant', 'content':'Why did the chicken cross the road'},   \n",
    "{'role':'user', 'content':'I don\\'t know'}  ]\n",
    "\n",
    "response = get_completion_from_messages(messages, temperature=1)\n",
    "print(response) #will give response according to previous conversation and the behaviour specified by the system."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2228b2c0",
   "metadata": {},
   "source": [
    "## JasonBOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061c32ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_messages(_):\n",
    "    prompt = inp.value_input\n",
    "    inp.value = ''\n",
    "    context.append({'role':'user', 'content':f\"{prompt}\"})\n",
    "    response = get_completion_from_messages(context) \n",
    "    context.append({'role':'assistant', 'content':f\"{response}\"})\n",
    "    panels.append(\n",
    "        pn.Row('User:', pn.pane.Markdown(prompt, width=600)))\n",
    "    panels.append(\n",
    "        pn.Row('Assistant:', pn.pane.Markdown(response, width=600, style={'background-color': '#F6F6F6'})))\n",
    " \n",
    "    return pn.Column(*panels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7afc6b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import panel as pn  # GUI\n",
    "pn.extension()\n",
    "\n",
    "panels = [] # collect display \n",
    "\n",
    "context = [ {'role':'system', 'content':\"\"\"\n",
    "You are an JasonBot.A chatbot that can give answers to questions about Jason.\n",
    "Only give answer if you can found the exact answer in the given information about the Jason.Do not create your own answer.If answer is not found then give the following answer \n",
    "```\n",
    "Sorry,I do not know.\n",
    "```\n",
    "\n",
    "Please use the following information about Jason to answer any question asked to you.\n",
    "```\n",
    "Name : Jason Derulo\n",
    "Age : 24\n",
    "Color : Brown\n",
    "Relationship Status : Not single\n",
    "Girlfriend Name : Nora Fatehi\n",
    "Mother Name : Angelina\n",
    "Father Name : Brad\n",
    "Sister Name : Kim\n",
    "Best Food : Paneer Curry\n",
    "Best Sports: Football\n",
    "Education : Graduate\n",
    "Alma Matter : Stanford\n",
    "Job Satus : AI Engineer at OpenAI\n",
    "Other features : Shy,Smart,Intelligent,Healthy\n",
    "Weight : 65kg\n",
    "```\n",
    "\"\"\"} ]  # accumulate messages\n",
    "\n",
    "\n",
    "inp = pn.widgets.TextInput(value=\"Hi\", placeholder='Enter text here…')\n",
    "button_conversation = pn.widgets.Button(name=\"Chat!\")\n",
    "\n",
    "interactive_conversation = pn.bind(collect_messages, button_conversation)\n",
    "\n",
    "dashboard = pn.Column(\n",
    "    inp,\n",
    "    pn.Row(button_conversation),\n",
    "    pn.panel(interactive_conversation, loading_indicator=True, height=300),\n",
    ")\n",
    "\n",
    "dashboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cadf459c",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
