{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spam mail filter using keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_csv=pd.read_csv(\"D:\\Desktop\\ML with pyhton\\datasets\\emails.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_csv.drop([\"Email No.\"],axis=1,inplace=True)\n",
    "data_csv=data_csv.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=data_csv.to_numpy(dtype='float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5172, 3001)\n"
     ]
    }
   ],
   "source": [
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "label=dataset[: , 3000].astype('int64')\n",
    "X=dataset[: ,:3000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive samples in data: 1500 (29.00% of total)\n"
     ]
    }
   ],
   "source": [
    "counts = np.bincount(label[:])\n",
    "print(\n",
    "    \"Number of positive samples in data: {} ({:.2f}% of total)\".format(\n",
    "        counts[1], 100 * float(counts[1]) / len(label)\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean=np.mean(X,axis=0)\n",
    "std=np.std(X,axis=0)\n",
    "mean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X-=mean\n",
    "X/=std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model =Sequential(\n",
    "    [\n",
    "    Dense(1000,activation='relu',input_shape=(X.shape[1],),kernel_regularizer='l2'),\n",
    "    Dense(100,activation='relu',kernel_regularizer='l2'),\n",
    "    Dense(10,activation='relu',kernel_regularizer='l2'),\n",
    "    Dense(1, activation='sigmoid',kernel_regularizer='l2'),\n",
    "]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 1000)              3001000   \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 100)               100100    \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                1010      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 3,102,121\n",
      "Trainable params: 3,102,121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3620 samples, validate on 1552 samples\n",
      "Epoch 1/150\n",
      "3620/3620 [==============================] - 11s 3ms/sample - loss: 0.2176 - fn: 21.0000 - fp: 36.0000 - tn: 2549.0000 - tp: 1014.0000 - precision: 0.9657 - recall: 0.9797 - val_loss: 0.2509 - val_fn: 21.0000 - val_fp: 33.0000 - val_tn: 1054.0000 - val_tp: 444.0000 - val_precision: 0.9308 - val_recall: 0.9548\n",
      "Epoch 2/150\n",
      "3620/3620 [==============================] - 5s 1ms/sample - loss: 0.1850 - fn: 18.0000 - fp: 29.0000 - tn: 2556.0000 - tp: 1017.0000 - precision: 0.9723 - recall: 0.9826 - val_loss: 0.2483 - val_fn: 11.0000 - val_fp: 58.0000 - val_tn: 1029.0000 - val_tp: 454.0000 - val_precision: 0.8867 - val_recall: 0.9763\n",
      "Epoch 3/150\n",
      "3620/3620 [==============================] - 5s 1ms/sample - loss: 0.1657 - fn: 13.0000 - fp: 29.0000 - tn: 2556.0000 - tp: 1022.0000 - precision: 0.9724 - recall: 0.9874 - val_loss: 0.2359 - val_fn: 11.0000 - val_fp: 53.0000 - val_tn: 1034.0000 - val_tp: 454.0000 - val_precision: 0.8955 - val_recall: 0.9763\n",
      "Epoch 4/150\n",
      "3620/3620 [==============================] - 5s 1ms/sample - loss: 0.1695 - fn: 23.0000 - fp: 28.0000 - tn: 2557.0000 - tp: 1012.0000 - precision: 0.9731 - recall: 0.9778 - val_loss: 0.2293 - val_fn: 14.0000 - val_fp: 45.0000 - val_tn: 1042.0000 - val_tp: 451.0000 - val_precision: 0.9093 - val_recall: 0.9699\n",
      "Epoch 5/150\n",
      "3620/3620 [==============================] - 5s 1ms/sample - loss: 0.1715 - fn: 19.0000 - fp: 33.0000 - tn: 2552.0000 - tp: 1016.0000 - precision: 0.9685 - recall: 0.9816 - val_loss: 0.2077 - val_fn: 36.0000 - val_fp: 22.0000 - val_tn: 1065.0000 - val_tp: 429.0000 - val_precision: 0.9512 - val_recall: 0.9226\n",
      "Epoch 6/150\n",
      "3620/3620 [==============================] - 5s 1ms/sample - loss: 0.1529 - fn: 11.0000 - fp: 21.0000 - tn: 2564.0000 - tp: 1024.0000 - precision: 0.9799 - recall: 0.9894 - val_loss: 0.1947 - val_fn: 16.0000 - val_fp: 21.0000 - val_tn: 1066.0000 - val_tp: 449.0000 - val_precision: 0.9553 - val_recall: 0.9656\n",
      "Epoch 7/150\n",
      "3620/3620 [==============================] - 5s 1ms/sample - loss: 0.1421 - fn: 6.0000 - fp: 18.0000 - tn: 2567.0000 - tp: 1029.0000 - precision: 0.9828 - recall: 0.9942 - val_loss: 0.1967 - val_fn: 14.0000 - val_fp: 25.0000 - val_tn: 1062.0000 - val_tp: 451.0000 - val_precision: 0.9475 - val_recall: 0.9699\n",
      "Epoch 8/150\n",
      "3620/3620 [==============================] - 5s 1ms/sample - loss: 0.1344 - fn: 3.0000 - fp: 14.0000 - tn: 2571.0000 - tp: 1032.0000 - precision: 0.9866 - recall: 0.9971 - val_loss: 0.1897 - val_fn: 32.0000 - val_fp: 17.0000 - val_tn: 1070.0000 - val_tp: 433.0000 - val_precision: 0.9622 - val_recall: 0.9312\n",
      "Epoch 9/150\n",
      "3620/3620 [==============================] - 5s 1ms/sample - loss: 0.1289 - fn: 5.0000 - fp: 11.0000 - tn: 2574.0000 - tp: 1030.0000 - precision: 0.9894 - recall: 0.9952 - val_loss: 0.1869 - val_fn: 28.0000 - val_fp: 17.0000 - val_tn: 1070.0000 - val_tp: 437.0000 - val_precision: 0.9626 - val_recall: 0.9398\n",
      "Epoch 10/150\n",
      "3620/3620 [==============================] - 5s 1ms/sample - loss: 0.1256 - fn: 2.0000 - fp: 10.0000 - tn: 2575.0000 - tp: 1033.0000 - precision: 0.9904 - recall: 0.9981 - val_loss: 0.2392 - val_fn: 97.0000 - val_fp: 15.0000 - val_tn: 1072.0000 - val_tp: 368.0000 - val_precision: 0.9608 - val_recall: 0.7914\n",
      "Epoch 11/150\n",
      "3620/3620 [==============================] - 5s 1ms/sample - loss: 0.1241 - fn: 6.0000 - fp: 11.0000 - tn: 2574.0000 - tp: 1029.0000 - precision: 0.9894 - recall: 0.9942 - val_loss: 0.1818 - val_fn: 22.0000 - val_fp: 19.0000 - val_tn: 1068.0000 - val_tp: 443.0000 - val_precision: 0.9589 - val_recall: 0.9527\n",
      "Epoch 12/150\n",
      "3620/3620 [==============================] - 5s 1ms/sample - loss: 0.1214 - fn: 3.0000 - fp: 12.0000 - tn: 2573.0000 - tp: 1032.0000 - precision: 0.9885 - recall: 0.9971 - val_loss: 0.1817 - val_fn: 18.0000 - val_fp: 22.0000 - val_tn: 1065.0000 - val_tp: 447.0000 - val_precision: 0.9531 - val_recall: 0.9613\n",
      "Epoch 13/150\n",
      "3620/3620 [==============================] - 5s 1ms/sample - loss: 0.1198 - fn: 2.0000 - fp: 9.0000 - tn: 2576.0000 - tp: 1033.0000 - precision: 0.9914 - recall: 0.9981 - val_loss: 0.1818 - val_fn: 19.0000 - val_fp: 21.0000 - val_tn: 1066.0000 - val_tp: 446.0000 - val_precision: 0.9550 - val_recall: 0.9591\n",
      "Epoch 14/150\n",
      "3620/3620 [==============================] - 5s 1ms/sample - loss: 0.1187 - fn: 1.0000 - fp: 10.0000 - tn: 2575.0000 - tp: 1034.0000 - precision: 0.9904 - recall: 0.9990 - val_loss: 0.1842 - val_fn: 16.0000 - val_fp: 23.0000 - val_tn: 1064.0000 - val_tp: 449.0000 - val_precision: 0.9513 - val_recall: 0.9656\n",
      "Epoch 15/150\n",
      "3620/3620 [==============================] - 5s 1ms/sample - loss: 0.1180 - fn: 1.0000 - fp: 9.0000 - tn: 2576.0000 - tp: 1034.0000 - precision: 0.9914 - recall: 0.9990 - val_loss: 0.1797 - val_fn: 22.0000 - val_fp: 21.0000 - val_tn: 1066.0000 - val_tp: 443.0000 - val_precision: 0.9547 - val_recall: 0.9527\n",
      "Epoch 16/150\n",
      "3620/3620 [==============================] - 5s 1ms/sample - loss: 0.1174 - fn: 2.0000 - fp: 10.0000 - tn: 2575.0000 - tp: 1033.0000 - precision: 0.9904 - recall: 0.9981 - val_loss: 0.1793 - val_fn: 25.0000 - val_fp: 19.0000 - val_tn: 1068.0000 - val_tp: 440.0000 - val_precision: 0.9586 - val_recall: 0.9462\n",
      "Epoch 17/150\n",
      "3620/3620 [==============================] - 5s 1ms/sample - loss: 0.1165 - fn: 1.0000 - fp: 9.0000 - tn: 2576.0000 - tp: 1034.0000 - precision: 0.9914 - recall: 0.9990 - val_loss: 0.1801 - val_fn: 24.0000 - val_fp: 18.0000 - val_tn: 1069.0000 - val_tp: 441.0000 - val_precision: 0.9608 - val_recall: 0.9484\n",
      "Epoch 18/150\n",
      "3620/3620 [==============================] - 5s 1ms/sample - loss: 0.1159 - fn: 1.0000 - fp: 9.0000 - tn: 2576.0000 - tp: 1034.0000 - precision: 0.9914 - recall: 0.9990 - val_loss: 0.1827 - val_fn: 18.0000 - val_fp: 23.0000 - val_tn: 1064.0000 - val_tp: 447.0000 - val_precision: 0.9511 - val_recall: 0.9613\n",
      "Epoch 19/150\n",
      "3620/3620 [==============================] - 5s 1ms/sample - loss: 0.1155 - fn: 1.0000 - fp: 9.0000 - tn: 2576.0000 - tp: 1034.0000 - precision: 0.9914 - recall: 0.9990 - val_loss: 0.1791 - val_fn: 26.0000 - val_fp: 18.0000 - val_tn: 1069.0000 - val_tp: 439.0000 - val_precision: 0.9606 - val_recall: 0.9441\n",
      "Epoch 20/150\n",
      "3620/3620 [==============================] - 5s 1ms/sample - loss: 0.1151 - fn: 2.0000 - fp: 9.0000 - tn: 2576.0000 - tp: 1033.0000 - precision: 0.9914 - recall: 0.9981 - val_loss: 0.1797 - val_fn: 24.0000 - val_fp: 19.0000 - val_tn: 1068.0000 - val_tp: 441.0000 - val_precision: 0.9587 - val_recall: 0.9484\n",
      "Epoch 21/150\n",
      "3620/3620 [==============================] - 5s 1ms/sample - loss: 0.1148 - fn: 1.0000 - fp: 9.0000 - tn: 2576.0000 - tp: 1034.0000 - precision: 0.9914 - recall: 0.9990 - val_loss: 0.1837 - val_fn: 17.0000 - val_fp: 24.0000 - val_tn: 1063.0000 - val_tp: 448.0000 - val_precision: 0.9492 - val_recall: 0.9634\n",
      "Epoch 22/150\n",
      "3620/3620 [==============================] - 5s 1ms/sample - loss: 0.1146 - fn: 1.0000 - fp: 9.0000 - tn: 2576.0000 - tp: 1034.0000 - precision: 0.9914 - recall: 0.9990 - val_loss: 0.1825 - val_fn: 18.0000 - val_fp: 21.0000 - val_tn: 1066.0000 - val_tp: 447.0000 - val_precision: 0.9551 - val_recall: 0.9613\n",
      "Epoch 23/150\n",
      "3620/3620 [==============================] - 5s 1ms/sample - loss: 0.1142 - fn: 1.0000 - fp: 9.0000 - tn: 2576.0000 - tp: 1034.0000 - precision: 0.9914 - recall: 0.9990 - val_loss: 0.1794 - val_fn: 25.0000 - val_fp: 18.0000 - val_tn: 1069.0000 - val_tp: 440.0000 - val_precision: 0.9607 - val_recall: 0.9462\n",
      "Epoch 24/150\n",
      "3620/3620 [==============================] - 5s 1ms/sample - loss: 0.1141 - fn: 1.0000 - fp: 9.0000 - tn: 2576.0000 - tp: 1034.0000 - precision: 0.9914 - recall: 0.9990 - val_loss: 0.1799 - val_fn: 23.0000 - val_fp: 20.0000 - val_tn: 1067.0000 - val_tp: 442.0000 - val_precision: 0.9567 - val_recall: 0.9505\n",
      "Epoch 25/150\n",
      "3620/3620 [==============================] - 5s 1ms/sample - loss: 0.1139 - fn: 1.0000 - fp: 9.0000 - tn: 2576.0000 - tp: 1034.0000 - precision: 0.9914 - recall: 0.9990 - val_loss: 0.1803 - val_fn: 22.0000 - val_fp: 21.0000 - val_tn: 1066.0000 - val_tp: 443.0000 - val_precision: 0.9547 - val_recall: 0.9527\n",
      "Epoch 26/150\n",
      "3620/3620 [==============================] - 5s 1ms/sample - loss: 0.1137 - fn: 1.0000 - fp: 9.0000 - tn: 2576.0000 - tp: 1034.0000 - precision: 0.9914 - recall: 0.9990 - val_loss: 0.1793 - val_fn: 24.0000 - val_fp: 18.0000 - val_tn: 1069.0000 - val_tp: 441.0000 - val_precision: 0.9608 - val_recall: 0.9484\n",
      "Epoch 27/150\n",
      "3620/3620 [==============================] - 5s 1ms/sample - loss: 0.1136 - fn: 1.0000 - fp: 9.0000 - tn: 2576.0000 - tp: 1034.0000 - precision: 0.9914 - recall: 0.9990 - val_loss: 0.1795 - val_fn: 24.0000 - val_fp: 19.0000 - val_tn: 1068.0000 - val_tp: 441.0000 - val_precision: 0.9587 - val_recall: 0.9484\n",
      "Epoch 28/150\n",
      "3620/3620 [==============================] - 5s 1ms/sample - loss: 0.1135 - fn: 1.0000 - fp: 9.0000 - tn: 2576.0000 - tp: 1034.0000 - precision: 0.9914 - recall: 0.9990 - val_loss: 0.1807 - val_fn: 22.0000 - val_fp: 21.0000 - val_tn: 1066.0000 - val_tp: 443.0000 - val_precision: 0.9547 - val_recall: 0.9527\n",
      "Epoch 29/150\n",
      "3620/3620 [==============================] - 5s 1ms/sample - loss: 0.1134 - fn: 1.0000 - fp: 9.0000 - tn: 2576.0000 - tp: 1034.0000 - precision: 0.9914 - recall: 0.9990 - val_loss: 0.1806 - val_fn: 22.0000 - val_fp: 21.0000 - val_tn: 1066.0000 - val_tp: 443.0000 - val_precision: 0.9547 - val_recall: 0.9527\n",
      "Epoch 30/150\n",
      "3620/3620 [==============================] - 5s 1ms/sample - loss: 0.1133 - fn: 1.0000 - fp: 9.0000 - tn: 2576.0000 - tp: 1034.0000 - precision: 0.9914 - recall: 0.9990 - val_loss: 0.1811 - val_fn: 21.0000 - val_fp: 21.0000 - val_tn: 1066.0000 - val_tp: 444.0000 - val_precision: 0.9548 - val_recall: 0.9548\n",
      "Epoch 31/150\n",
      "3620/3620 [==============================] - 5s 1ms/sample - loss: 0.1132 - fn: 1.0000 - fp: 9.0000 - tn: 2576.0000 - tp: 1034.0000 - precision: 0.9914 - recall: 0.9990 - val_loss: 0.1806 - val_fn: 22.0000 - val_fp: 21.0000 - val_tn: 1066.0000 - val_tp: 443.0000 - val_precision: 0.9547 - val_recall: 0.9527\n",
      "Epoch 32/150\n",
      "3620/3620 [==============================] - 5s 1ms/sample - loss: 0.1131 - fn: 1.0000 - fp: 8.0000 - tn: 2577.0000 - tp: 1034.0000 - precision: 0.9923 - recall: 0.9990 - val_loss: 0.1816 - val_fn: 19.0000 - val_fp: 21.0000 - val_tn: 1066.0000 - val_tp: 446.0000 - val_precision: 0.9550 - val_recall: 0.9591\n",
      "Epoch 33/150\n",
      "3620/3620 [==============================] - 5s 1ms/sample - loss: 0.1131 - fn: 1.0000 - fp: 9.0000 - tn: 2576.0000 - tp: 1034.0000 - precision: 0.9914 - recall: 0.9990 - val_loss: 0.1811 - val_fn: 22.0000 - val_fp: 21.0000 - val_tn: 1066.0000 - val_tp: 443.0000 - val_precision: 0.9547 - val_recall: 0.9527\n",
      "Epoch 34/150\n",
      "3620/3620 [==============================] - 5s 1ms/sample - loss: 0.1130 - fn: 1.0000 - fp: 9.0000 - tn: 2576.0000 - tp: 1034.0000 - precision: 0.9914 - recall: 0.9990 - val_loss: 0.1815 - val_fn: 19.0000 - val_fp: 21.0000 - val_tn: 1066.0000 - val_tp: 446.0000 - val_precision: 0.9550 - val_recall: 0.9591\n",
      "Epoch 35/150\n",
      "3620/3620 [==============================] - 5s 1ms/sample - loss: 0.1130 - fn: 1.0000 - fp: 9.0000 - tn: 2576.0000 - tp: 1034.0000 - precision: 0.9914 - recall: 0.9990 - val_loss: 0.1811 - val_fn: 22.0000 - val_fp: 21.0000 - val_tn: 1066.0000 - val_tp: 443.0000 - val_precision: 0.9547 - val_recall: 0.9527\n",
      "Epoch 36/150\n",
      "3620/3620 [==============================] - 5s 1ms/sample - loss: 0.1129 - fn: 1.0000 - fp: 9.0000 - tn: 2576.0000 - tp: 1034.0000 - precision: 0.9914 - recall: 0.9990 - val_loss: 0.1808 - val_fn: 22.0000 - val_fp: 21.0000 - val_tn: 1066.0000 - val_tp: 443.0000 - val_precision: 0.9547 - val_recall: 0.9527\n",
      "Epoch 37/150\n",
      "3620/3620 [==============================] - 5s 1ms/sample - loss: 0.1129 - fn: 1.0000 - fp: 9.0000 - tn: 2576.0000 - tp: 1034.0000 - precision: 0.9914 - recall: 0.9990 - val_loss: 0.1808 - val_fn: 22.0000 - val_fp: 21.0000 - val_tn: 1066.0000 - val_tp: 443.0000 - val_precision: 0.9547 - val_recall: 0.9527\n",
      "Epoch 38/150\n",
      "3620/3620 [==============================] - 5s 1ms/sample - loss: 0.1128 - fn: 1.0000 - fp: 9.0000 - tn: 2576.0000 - tp: 1034.0000 - precision: 0.9914 - recall: 0.9990 - val_loss: 0.1810 - val_fn: 22.0000 - val_fp: 21.0000 - val_tn: 1066.0000 - val_tp: 443.0000 - val_precision: 0.9547 - val_recall: 0.9527\n",
      "Epoch 39/150\n",
      "3620/3620 [==============================] - 5s 1ms/sample - loss: 0.1128 - fn: 1.0000 - fp: 9.0000 - tn: 2576.0000 - tp: 1034.0000 - precision: 0.9914 - recall: 0.9990 - val_loss: 0.1809 - val_fn: 22.0000 - val_fp: 21.0000 - val_tn: 1066.0000 - val_tp: 443.0000 - val_precision: 0.9547 - val_recall: 0.9527\n",
      "Epoch 40/150\n",
      "3620/3620 [==============================] - 5s 1ms/sample - loss: 0.1128 - fn: 1.0000 - fp: 9.0000 - tn: 2576.0000 - tp: 1034.0000 - precision: 0.9914 - recall: 0.9990 - val_loss: 0.1810 - val_fn: 22.0000 - val_fp: 21.0000 - val_tn: 1066.0000 - val_tp: 443.0000 - val_precision: 0.9547 - val_recall: 0.9527\n",
      "Epoch 41/150\n",
      "3620/3620 [==============================] - 5s 1ms/sample - loss: 0.1128 - fn: 1.0000 - fp: 9.0000 - tn: 2576.0000 - tp: 1034.0000 - precision: 0.9914 - recall: 0.9990 - val_loss: 0.1810 - val_fn: 22.0000 - val_fp: 21.0000 - val_tn: 1066.0000 - val_tp: 443.0000 - val_precision: 0.9547 - val_recall: 0.9527\n",
      "Epoch 42/150\n",
      "3620/3620 [==============================] - 5s 1ms/sample - loss: 0.1128 - fn: 1.0000 - fp: 9.0000 - tn: 2576.0000 - tp: 1034.0000 - precision: 0.9914 - recall: 0.9990 - val_loss: 0.1808 - val_fn: 22.0000 - val_fp: 21.0000 - val_tn: 1066.0000 - val_tp: 443.0000 - val_precision: 0.9547 - val_recall: 0.9527\n",
      "Epoch 43/150\n",
      "3620/3620 [==============================] - 5s 1ms/sample - loss: 0.1127 - fn: 1.0000 - fp: 9.0000 - tn: 2576.0000 - tp: 1034.0000 - precision: 0.9914 - recall: 0.9990 - val_loss: 0.1809 - val_fn: 22.0000 - val_fp: 21.0000 - val_tn: 1066.0000 - val_tp: 443.0000 - val_precision: 0.9547 - val_recall: 0.9527\n",
      "Epoch 44/150\n",
      "3620/3620 [==============================] - 5s 1ms/sample - loss: 0.1127 - fn: 1.0000 - fp: 9.0000 - tn: 2576.0000 - tp: 1034.0000 - precision: 0.9914 - recall: 0.9990 - val_loss: 0.1809 - val_fn: 22.0000 - val_fp: 21.0000 - val_tn: 1066.0000 - val_tp: 443.0000 - val_precision: 0.9547 - val_recall: 0.9527\n",
      "Epoch 45/150\n",
      "3620/3620 [==============================] - 5s 1ms/sample - loss: 0.1127 - fn: 1.0000 - fp: 9.0000 - tn: 2576.0000 - tp: 1034.0000 - precision: 0.9914 - recall: 0.9990 - val_loss: 0.1809 - val_fn: 22.0000 - val_fp: 21.0000 - val_tn: 1066.0000 - val_tp: 443.0000 - val_precision: 0.9547 - val_recall: 0.9527\n",
      "Epoch 46/150\n",
      "3620/3620 [==============================] - 5s 1ms/sample - loss: 0.1127 - fn: 1.0000 - fp: 9.0000 - tn: 2576.0000 - tp: 1034.0000 - precision: 0.9914 - recall: 0.9990 - val_loss: 0.1809 - val_fn: 22.0000 - val_fp: 21.0000 - val_tn: 1066.0000 - val_tp: 443.0000 - val_precision: 0.9547 - val_recall: 0.9527\n",
      "Epoch 47/150\n",
      "3620/3620 [==============================] - 5s 1ms/sample - loss: 0.1127 - fn: 1.0000 - fp: 9.0000 - tn: 2576.0000 - tp: 1034.0000 - precision: 0.9914 - recall: 0.9990 - val_loss: 0.1808 - val_fn: 22.0000 - val_fp: 21.0000 - val_tn: 1066.0000 - val_tp: 443.0000 - val_precision: 0.9547 - val_recall: 0.9527\n",
      "Epoch 48/150\n",
      "3620/3620 [==============================] - 5s 1ms/sample - loss: 0.1127 - fn: 1.0000 - fp: 9.0000 - tn: 2576.0000 - tp: 1034.0000 - precision: 0.9914 - recall: 0.9990 - val_loss: 0.1809 - val_fn: 22.0000 - val_fp: 21.0000 - val_tn: 1066.0000 - val_tp: 443.0000 - val_precision: 0.9547 - val_recall: 0.9527\n",
      "Epoch 49/150\n",
      "3620/3620 [==============================] - 5s 1ms/sample - loss: 0.1127 - fn: 1.0000 - fp: 9.0000 - tn: 2576.0000 - tp: 1034.0000 - precision: 0.9914 - recall: 0.9990 - val_loss: 0.1809 - val_fn: 22.0000 - val_fp: 21.0000 - val_tn: 1066.0000 - val_tp: 443.0000 - val_precision: 0.9547 - val_recall: 0.9527\n",
      "Epoch 50/150\n",
      "3620/3620 [==============================] - 5s 1ms/sample - loss: 0.1126 - fn: 1.0000 - fp: 9.0000 - tn: 2576.0000 - tp: 1034.0000 - precision: 0.9914 - recall: 0.9990 - val_loss: 0.1810 - val_fn: 22.0000 - val_fp: 21.0000 - val_tn: 1066.0000 - val_tp: 443.0000 - val_precision: 0.9547 - val_recall: 0.9527\n",
      "Epoch 51/150\n",
      "3620/3620 [==============================] - 5s 1ms/sample - loss: 0.1126 - fn: 1.0000 - fp: 9.0000 - tn: 2576.0000 - tp: 1034.0000 - precision: 0.9914 - recall: 0.9990 - val_loss: 0.1810 - val_fn: 22.0000 - val_fp: 21.0000 - val_tn: 1066.0000 - val_tp: 443.0000 - val_precision: 0.9547 - val_recall: 0.9527\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/150\n",
      "3620/3620 [==============================] - 5s 1ms/sample - loss: 0.1126 - fn: 1.0000 - fp: 9.0000 - tn: 2576.0000 - tp: 1034.0000 - precision: 0.9914 - recall: 0.9990 - val_loss: 0.1810 - val_fn: 22.0000 - val_fp: 21.0000 - val_tn: 1066.0000 - val_tp: 443.0000 - val_precision: 0.9547 - val_recall: 0.9527\n",
      "Epoch 53/150\n",
      "3620/3620 [==============================] - 5s 1ms/sample - loss: 0.1126 - fn: 1.0000 - fp: 9.0000 - tn: 2576.0000 - tp: 1034.0000 - precision: 0.9914 - recall: 0.9990 - val_loss: 0.1810 - val_fn: 22.0000 - val_fp: 21.0000 - val_tn: 1066.0000 - val_tp: 443.0000 - val_precision: 0.9547 - val_recall: 0.9527\n",
      "Epoch 54/150\n",
      "3620/3620 [==============================] - 5s 1ms/sample - loss: 0.1126 - fn: 1.0000 - fp: 9.0000 - tn: 2576.0000 - tp: 1034.0000 - precision: 0.9914 - recall: 0.9990 - val_loss: 0.1810 - val_fn: 22.0000 - val_fp: 21.0000 - val_tn: 1066.0000 - val_tp: 443.0000 - val_precision: 0.9547 - val_recall: 0.9527\n",
      "Epoch 55/150\n",
      "3620/3620 [==============================] - 5s 1ms/sample - loss: 0.1126 - fn: 1.0000 - fp: 9.0000 - tn: 2576.0000 - tp: 1034.0000 - precision: 0.9914 - recall: 0.9990 - val_loss: 0.1810 - val_fn: 22.0000 - val_fp: 21.0000 - val_tn: 1066.0000 - val_tp: 443.0000 - val_precision: 0.9547 - val_recall: 0.9527\n",
      "Epoch 56/150\n",
      "3620/3620 [==============================] - 5s 1ms/sample - loss: 0.1126 - fn: 1.0000 - fp: 9.0000 - tn: 2576.0000 - tp: 1034.0000 - precision: 0.9914 - recall: 0.9990 - val_loss: 0.1810 - val_fn: 22.0000 - val_fp: 21.0000 - val_tn: 1066.0000 - val_tp: 443.0000 - val_precision: 0.9547 - val_recall: 0.9527\n",
      "Epoch 57/150\n",
      "3620/3620 [==============================] - 5s 1ms/sample - loss: 0.1126 - fn: 1.0000 - fp: 9.0000 - tn: 2576.0000 - tp: 1034.0000 - precision: 0.9914 - recall: 0.9990 - val_loss: 0.1810 - val_fn: 22.0000 - val_fp: 21.0000 - val_tn: 1066.0000 - val_tp: 443.0000 - val_precision: 0.9547 - val_recall: 0.9527\n",
      "Epoch 58/150\n",
      "3620/3620 [==============================] - 5s 1ms/sample - loss: 0.1126 - fn: 1.0000 - fp: 9.0000 - tn: 2576.0000 - tp: 1034.0000 - precision: 0.9914 - recall: 0.9990 - val_loss: 0.1810 - val_fn: 22.0000 - val_fp: 21.0000 - val_tn: 1066.0000 - val_tp: 443.0000 - val_precision: 0.9547 - val_recall: 0.9527\n",
      "Epoch 59/150\n",
      "3620/3620 [==============================] - 5s 1ms/sample - loss: 0.1126 - fn: 1.0000 - fp: 9.0000 - tn: 2576.0000 - tp: 1034.0000 - precision: 0.9914 - recall: 0.9990 - val_loss: 0.1810 - val_fn: 22.0000 - val_fp: 21.0000 - val_tn: 1066.0000 - val_tp: 443.0000 - val_precision: 0.9547 - val_recall: 0.9527\n",
      "Epoch 60/150\n",
      "3620/3620 [==============================] - 5s 1ms/sample - loss: 0.1126 - fn: 1.0000 - fp: 9.0000 - tn: 2576.0000 - tp: 1034.0000 - precision: 0.9914 - recall: 0.9990 - val_loss: 0.1810 - val_fn: 22.0000 - val_fp: 21.0000 - val_tn: 1066.0000 - val_tp: 443.0000 - val_precision: 0.9547 - val_recall: 0.9527\n",
      "Epoch 61/150\n",
      "3620/3620 [==============================] - 5s 1ms/sample - loss: 0.1126 - fn: 1.0000 - fp: 9.0000 - tn: 2576.0000 - tp: 1034.0000 - precision: 0.9914 - recall: 0.9990 - val_loss: 0.1810 - val_fn: 22.0000 - val_fp: 21.0000 - val_tn: 1066.0000 - val_tp: 443.0000 - val_precision: 0.9547 - val_recall: 0.9527\n",
      "Epoch 62/150\n",
      "3620/3620 [==============================] - 5s 1ms/sample - loss: 0.1126 - fn: 1.0000 - fp: 9.0000 - tn: 2576.0000 - tp: 1034.0000 - precision: 0.9914 - recall: 0.9990 - val_loss: 0.1810 - val_fn: 22.0000 - val_fp: 21.0000 - val_tn: 1066.0000 - val_tp: 443.0000 - val_precision: 0.9547 - val_recall: 0.9527\n",
      "Epoch 63/150\n",
      "3620/3620 [==============================] - 5s 1ms/sample - loss: 0.1126 - fn: 1.0000 - fp: 9.0000 - tn: 2576.0000 - tp: 1034.0000 - precision: 0.9914 - recall: 0.9990 - val_loss: 0.1810 - val_fn: 22.0000 - val_fp: 21.0000 - val_tn: 1066.0000 - val_tp: 443.0000 - val_precision: 0.9547 - val_recall: 0.9527\n",
      "Epoch 64/150\n",
      "3620/3620 [==============================] - 5s 1ms/sample - loss: 0.1126 - fn: 1.0000 - fp: 9.0000 - tn: 2576.0000 - tp: 1034.0000 - precision: 0.9914 - recall: 0.9990 - val_loss: 0.1810 - val_fn: 22.0000 - val_fp: 21.0000 - val_tn: 1066.0000 - val_tp: 443.0000 - val_precision: 0.9547 - val_recall: 0.9527\n",
      "Epoch 65/150\n",
      "3620/3620 [==============================] - 5s 1ms/sample - loss: 0.1126 - fn: 1.0000 - fp: 9.0000 - tn: 2576.0000 - tp: 1034.0000 - precision: 0.9914 - recall: 0.9990 - val_loss: 0.1810 - val_fn: 22.0000 - val_fp: 21.0000 - val_tn: 1066.0000 - val_tp: 443.0000 - val_precision: 0.9547 - val_recall: 0.9527\n",
      "Epoch 66/150\n",
      "3620/3620 [==============================] - 5s 1ms/sample - loss: 0.1126 - fn: 1.0000 - fp: 9.0000 - tn: 2576.0000 - tp: 1034.0000 - precision: 0.9914 - recall: 0.9990 - val_loss: 0.1810 - val_fn: 22.0000 - val_fp: 21.0000 - val_tn: 1066.0000 - val_tp: 443.0000 - val_precision: 0.9547 - val_recall: 0.9527\n",
      "Epoch 67/150\n",
      "3620/3620 [==============================] - 5s 1ms/sample - loss: 0.1126 - fn: 1.0000 - fp: 9.0000 - tn: 2576.0000 - tp: 1034.0000 - precision: 0.9914 - recall: 0.9990 - val_loss: 0.1810 - val_fn: 22.0000 - val_fp: 21.0000 - val_tn: 1066.0000 - val_tp: 443.0000 - val_precision: 0.9547 - val_recall: 0.9527\n",
      "Epoch 68/150\n",
      "3620/3620 [==============================] - 5s 1ms/sample - loss: 0.1126 - fn: 1.0000 - fp: 9.0000 - tn: 2576.0000 - tp: 1034.0000 - precision: 0.9914 - recall: 0.9990 - val_loss: 0.1810 - val_fn: 22.0000 - val_fp: 21.0000 - val_tn: 1066.0000 - val_tp: 443.0000 - val_precision: 0.9547 - val_recall: 0.9527\n",
      "Epoch 69/150\n",
      "3620/3620 [==============================] - 5s 1ms/sample - loss: 0.1126 - fn: 1.0000 - fp: 9.0000 - tn: 2576.0000 - tp: 1034.0000 - precision: 0.9914 - recall: 0.9990 - val_loss: 0.1810 - val_fn: 22.0000 - val_fp: 21.0000 - val_tn: 1066.0000 - val_tp: 443.0000 - val_precision: 0.9547 - val_recall: 0.9527\n",
      "Epoch 70/150\n",
      "3620/3620 [==============================] - 5s 1ms/sample - loss: 0.1126 - fn: 1.0000 - fp: 9.0000 - tn: 2576.0000 - tp: 1034.0000 - precision: 0.9914 - recall: 0.9990 - val_loss: 0.1810 - val_fn: 22.0000 - val_fp: 21.0000 - val_tn: 1066.0000 - val_tp: 443.0000 - val_precision: 0.9547 - val_recall: 0.9527\n",
      "Epoch 71/150\n",
      "3620/3620 [==============================] - 5s 1ms/sample - loss: 0.1126 - fn: 1.0000 - fp: 9.0000 - tn: 2576.0000 - tp: 1034.0000 - precision: 0.9914 - recall: 0.9990 - val_loss: 0.1810 - val_fn: 22.0000 - val_fp: 21.0000 - val_tn: 1066.0000 - val_tp: 443.0000 - val_precision: 0.9547 - val_recall: 0.9527\n",
      "Epoch 72/150\n",
      "3620/3620 [==============================] - 5s 1ms/sample - loss: 0.1126 - fn: 1.0000 - fp: 9.0000 - tn: 2576.0000 - tp: 1034.0000 - precision: 0.9914 - recall: 0.9990 - val_loss: 0.1810 - val_fn: 22.0000 - val_fp: 21.0000 - val_tn: 1066.0000 - val_tp: 443.0000 - val_precision: 0.9547 - val_recall: 0.9527\n",
      "Epoch 73/150\n",
      "3620/3620 [==============================] - 5s 1ms/sample - loss: 0.1126 - fn: 1.0000 - fp: 9.0000 - tn: 2576.0000 - tp: 1034.0000 - precision: 0.9914 - recall: 0.9990 - val_loss: 0.1810 - val_fn: 22.0000 - val_fp: 21.0000 - val_tn: 1066.0000 - val_tp: 443.0000 - val_precision: 0.9547 - val_recall: 0.9527\n",
      "Epoch 74/150\n",
      "3620/3620 [==============================] - 5s 1ms/sample - loss: 0.1126 - fn: 1.0000 - fp: 9.0000 - tn: 2576.0000 - tp: 1034.0000 - precision: 0.9914 - recall: 0.9990 - val_loss: 0.1810 - val_fn: 22.0000 - val_fp: 21.0000 - val_tn: 1066.0000 - val_tp: 443.0000 - val_precision: 0.9547 - val_recall: 0.9527\n",
      "Epoch 75/150\n",
      "3620/3620 [==============================] - 5s 1ms/sample - loss: 0.1126 - fn: 1.0000 - fp: 9.0000 - tn: 2576.0000 - tp: 1034.0000 - precision: 0.9914 - recall: 0.9990 - val_loss: 0.1810 - val_fn: 22.0000 - val_fp: 21.0000 - val_tn: 1066.0000 - val_tp: 443.0000 - val_precision: 0.9547 - val_recall: 0.9527\n",
      "Epoch 76/150\n",
      "3620/3620 [==============================] - 5s 1ms/sample - loss: 0.1126 - fn: 1.0000 - fp: 9.0000 - tn: 2576.0000 - tp: 1034.0000 - precision: 0.9914 - recall: 0.9990 - val_loss: 0.1810 - val_fn: 22.0000 - val_fp: 21.0000 - val_tn: 1066.0000 - val_tp: 443.0000 - val_precision: 0.9547 - val_recall: 0.9527\n",
      "Epoch 77/150\n",
      "3620/3620 [==============================] - 5s 1ms/sample - loss: 0.1126 - fn: 1.0000 - fp: 9.0000 - tn: 2576.0000 - tp: 1034.0000 - precision: 0.9914 - recall: 0.9990 - val_loss: 0.1810 - val_fn: 22.0000 - val_fp: 21.0000 - val_tn: 1066.0000 - val_tp: 443.0000 - val_precision: 0.9547 - val_recall: 0.9527\n",
      "Epoch 78/150\n",
      "3620/3620 [==============================] - 5s 1ms/sample - loss: 0.1126 - fn: 1.0000 - fp: 9.0000 - tn: 2576.0000 - tp: 1034.0000 - precision: 0.9914 - recall: 0.9990 - val_loss: 0.1810 - val_fn: 22.0000 - val_fp: 21.0000 - val_tn: 1066.0000 - val_tp: 443.0000 - val_precision: 0.9547 - val_recall: 0.9527\n",
      "Epoch 79/150\n",
      "3620/3620 [==============================] - 5s 1ms/sample - loss: 0.1126 - fn: 1.0000 - fp: 9.0000 - tn: 2576.0000 - tp: 1034.0000 - precision: 0.9914 - recall: 0.9990 - val_loss: 0.1810 - val_fn: 22.0000 - val_fp: 21.0000 - val_tn: 1066.0000 - val_tp: 443.0000 - val_precision: 0.9547 - val_recall: 0.9527\n",
      "Epoch 80/150\n",
      "3620/3620 [==============================] - 5s 1ms/sample - loss: 0.1126 - fn: 1.0000 - fp: 9.0000 - tn: 2576.0000 - tp: 1034.0000 - precision: 0.9914 - recall: 0.9990 - val_loss: 0.1810 - val_fn: 22.0000 - val_fp: 21.0000 - val_tn: 1066.0000 - val_tp: 443.0000 - val_precision: 0.9547 - val_recall: 0.9527\n",
      "Epoch 81/150\n",
      "3620/3620 [==============================] - 5s 1ms/sample - loss: 0.1126 - fn: 1.0000 - fp: 9.0000 - tn: 2576.0000 - tp: 1034.0000 - precision: 0.9914 - recall: 0.9990 - val_loss: 0.1810 - val_fn: 22.0000 - val_fp: 21.0000 - val_tn: 1066.0000 - val_tp: 443.0000 - val_precision: 0.9547 - val_recall: 0.9527\n",
      "Epoch 82/150\n",
      "3620/3620 [==============================] - 5s 1ms/sample - loss: 0.1126 - fn: 1.0000 - fp: 9.0000 - tn: 2576.0000 - tp: 1034.0000 - precision: 0.9914 - recall: 0.9990 - val_loss: 0.1810 - val_fn: 22.0000 - val_fp: 21.0000 - val_tn: 1066.0000 - val_tp: 443.0000 - val_precision: 0.9547 - val_recall: 0.9527\n",
      "Epoch 83/150\n",
      "3620/3620 [==============================] - 5s 1ms/sample - loss: 0.1126 - fn: 1.0000 - fp: 9.0000 - tn: 2576.0000 - tp: 1034.0000 - precision: 0.9914 - recall: 0.9990 - val_loss: 0.1810 - val_fn: 22.0000 - val_fp: 21.0000 - val_tn: 1066.0000 - val_tp: 443.0000 - val_precision: 0.9547 - val_recall: 0.9527\n",
      "Epoch 84/150\n",
      "3620/3620 [==============================] - 5s 1ms/sample - loss: 0.1126 - fn: 1.0000 - fp: 9.0000 - tn: 2576.0000 - tp: 1034.0000 - precision: 0.9914 - recall: 0.9990 - val_loss: 0.1810 - val_fn: 22.0000 - val_fp: 21.0000 - val_tn: 1066.0000 - val_tp: 443.0000 - val_precision: 0.9547 - val_recall: 0.9527\n",
      "Epoch 85/150\n",
      "3620/3620 [==============================] - 5s 1ms/sample - loss: 0.1126 - fn: 1.0000 - fp: 9.0000 - tn: 2576.0000 - tp: 1034.0000 - precision: 0.9914 - recall: 0.9990 - val_loss: 0.1810 - val_fn: 22.0000 - val_fp: 21.0000 - val_tn: 1066.0000 - val_tp: 443.0000 - val_precision: 0.9547 - val_recall: 0.9527\n",
      "Epoch 86/150\n",
      "3620/3620 [==============================] - 5s 1ms/sample - loss: 0.1126 - fn: 1.0000 - fp: 9.0000 - tn: 2576.0000 - tp: 1034.0000 - precision: 0.9914 - recall: 0.9990 - val_loss: 0.1810 - val_fn: 22.0000 - val_fp: 21.0000 - val_tn: 1066.0000 - val_tp: 443.0000 - val_precision: 0.9547 - val_recall: 0.9527\n",
      "Epoch 87/150\n",
      "3620/3620 [==============================] - 5s 1ms/sample - loss: 0.1126 - fn: 1.0000 - fp: 9.0000 - tn: 2576.0000 - tp: 1034.0000 - precision: 0.9914 - recall: 0.9990 - val_loss: 0.1810 - val_fn: 22.0000 - val_fp: 21.0000 - val_tn: 1066.0000 - val_tp: 443.0000 - val_precision: 0.9547 - val_recall: 0.9527\n",
      "Epoch 88/150\n",
      "3620/3620 [==============================] - 5s 1ms/sample - loss: 0.1126 - fn: 1.0000 - fp: 9.0000 - tn: 2576.0000 - tp: 1034.0000 - precision: 0.9914 - recall: 0.9990 - val_loss: 0.1810 - val_fn: 22.0000 - val_fp: 21.0000 - val_tn: 1066.0000 - val_tp: 443.0000 - val_precision: 0.9547 - val_recall: 0.9527\n",
      "Epoch 89/150\n",
      "3620/3620 [==============================] - 5s 1ms/sample - loss: 0.1126 - fn: 1.0000 - fp: 9.0000 - tn: 2576.0000 - tp: 1034.0000 - precision: 0.9914 - recall: 0.9990 - val_loss: 0.1810 - val_fn: 22.0000 - val_fp: 21.0000 - val_tn: 1066.0000 - val_tp: 443.0000 - val_precision: 0.9547 - val_recall: 0.9527\n",
      "Epoch 90/150\n",
      "3620/3620 [==============================] - 5s 1ms/sample - loss: 0.1126 - fn: 1.0000 - fp: 9.0000 - tn: 2576.0000 - tp: 1034.0000 - precision: 0.9914 - recall: 0.9990 - val_loss: 0.1810 - val_fn: 22.0000 - val_fp: 21.0000 - val_tn: 1066.0000 - val_tp: 443.0000 - val_precision: 0.9547 - val_recall: 0.9527\n",
      "Epoch 91/150\n",
      "3620/3620 [==============================] - 5s 1ms/sample - loss: 0.1126 - fn: 1.0000 - fp: 9.0000 - tn: 2576.0000 - tp: 1034.0000 - precision: 0.9914 - recall: 0.9990 - val_loss: 0.1810 - val_fn: 22.0000 - val_fp: 21.0000 - val_tn: 1066.0000 - val_tp: 443.0000 - val_precision: 0.9547 - val_recall: 0.9527\n",
      "Epoch 92/150\n",
      "3620/3620 [==============================] - 5s 1ms/sample - loss: 0.1126 - fn: 1.0000 - fp: 9.0000 - tn: 2576.0000 - tp: 1034.0000 - precision: 0.9914 - recall: 0.9990 - val_loss: 0.1810 - val_fn: 22.0000 - val_fp: 21.0000 - val_tn: 1066.0000 - val_tp: 443.0000 - val_precision: 0.9547 - val_recall: 0.9527\n",
      "Epoch 93/150\n",
      "3620/3620 [==============================] - 5s 1ms/sample - loss: 0.1126 - fn: 1.0000 - fp: 9.0000 - tn: 2576.0000 - tp: 1034.0000 - precision: 0.9914 - recall: 0.9990 - val_loss: 0.1810 - val_fn: 22.0000 - val_fp: 21.0000 - val_tn: 1066.0000 - val_tp: 443.0000 - val_precision: 0.9547 - val_recall: 0.9527\n",
      "Epoch 94/150\n",
      "3620/3620 [==============================] - 5s 1ms/sample - loss: 0.1126 - fn: 1.0000 - fp: 9.0000 - tn: 2576.0000 - tp: 1034.0000 - precision: 0.9914 - recall: 0.9990 - val_loss: 0.1810 - val_fn: 22.0000 - val_fp: 21.0000 - val_tn: 1066.0000 - val_tp: 443.0000 - val_precision: 0.9547 - val_recall: 0.9527\n",
      "Epoch 95/150\n",
      "3620/3620 [==============================] - 5s 1ms/sample - loss: 0.1126 - fn: 1.0000 - fp: 9.0000 - tn: 2576.0000 - tp: 1034.0000 - precision: 0.9914 - recall: 0.9990 - val_loss: 0.1810 - val_fn: 22.0000 - val_fp: 21.0000 - val_tn: 1066.0000 - val_tp: 443.0000 - val_precision: 0.9547 - val_recall: 0.9527\n",
      "Epoch 96/150\n",
      "3620/3620 [==============================] - 5s 1ms/sample - loss: 0.1126 - fn: 1.0000 - fp: 9.0000 - tn: 2576.0000 - tp: 1034.0000 - precision: 0.9914 - recall: 0.9990 - val_loss: 0.1810 - val_fn: 22.0000 - val_fp: 21.0000 - val_tn: 1066.0000 - val_tp: 443.0000 - val_precision: 0.9547 - val_recall: 0.9527\n",
      "Epoch 97/150\n",
      "3620/3620 [==============================] - 6s 2ms/sample - loss: 0.1126 - fn: 1.0000 - fp: 9.0000 - tn: 2576.0000 - tp: 1034.0000 - precision: 0.9914 - recall: 0.9990 - val_loss: 0.1810 - val_fn: 22.0000 - val_fp: 21.0000 - val_tn: 1066.0000 - val_tp: 443.0000 - val_precision: 0.9547 - val_recall: 0.9527\n",
      "Epoch 98/150\n",
      "3620/3620 [==============================] - 5s 1ms/sample - loss: 0.1126 - fn: 1.0000 - fp: 9.0000 - tn: 2576.0000 - tp: 1034.0000 - precision: 0.9914 - recall: 0.9990 - val_loss: 0.1810 - val_fn: 22.0000 - val_fp: 21.0000 - val_tn: 1066.0000 - val_tp: 443.0000 - val_precision: 0.9547 - val_recall: 0.9527\n",
      "Epoch 99/150\n",
      "3620/3620 [==============================] - 5s 1ms/sample - loss: 0.1126 - fn: 1.0000 - fp: 9.0000 - tn: 2576.0000 - tp: 1034.0000 - precision: 0.9914 - recall: 0.9990 - val_loss: 0.1810 - val_fn: 22.0000 - val_fp: 21.0000 - val_tn: 1066.0000 - val_tp: 443.0000 - val_precision: 0.9547 - val_recall: 0.9527\n",
      "Epoch 100/150\n",
      "3620/3620 [==============================] - 5s 1ms/sample - loss: 0.1126 - fn: 1.0000 - fp: 9.0000 - tn: 2576.0000 - tp: 1034.0000 - precision: 0.9914 - recall: 0.9990 - val_loss: 0.1810 - val_fn: 22.0000 - val_fp: 21.0000 - val_tn: 1066.0000 - val_tp: 443.0000 - val_precision: 0.9547 - val_recall: 0.9527\n",
      "Epoch 101/150\n",
      "3620/3620 [==============================] - 5s 1ms/sample - loss: 0.1126 - fn: 1.0000 - fp: 9.0000 - tn: 2576.0000 - tp: 1034.0000 - precision: 0.9914 - recall: 0.9990 - val_loss: 0.1810 - val_fn: 22.0000 - val_fp: 21.0000 - val_tn: 1066.0000 - val_tp: 443.0000 - val_precision: 0.9547 - val_recall: 0.9527\n",
      "Epoch 102/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3620/3620 [==============================] - 5s 1ms/sample - loss: 0.1126 - fn: 1.0000 - fp: 9.0000 - tn: 2576.0000 - tp: 1034.0000 - precision: 0.9914 - recall: 0.9990 - val_loss: 0.1810 - val_fn: 22.0000 - val_fp: 21.0000 - val_tn: 1066.0000 - val_tp: 443.0000 - val_precision: 0.9547 - val_recall: 0.9527\n",
      "Epoch 103/150\n",
      "3620/3620 [==============================] - 5s 1ms/sample - loss: 0.1126 - fn: 1.0000 - fp: 9.0000 - tn: 2576.0000 - tp: 1034.0000 - precision: 0.9914 - recall: 0.9990 - val_loss: 0.1810 - val_fn: 22.0000 - val_fp: 21.0000 - val_tn: 1066.0000 - val_tp: 443.0000 - val_precision: 0.9547 - val_recall: 0.9527\n",
      "Epoch 104/150\n",
      "3620/3620 [==============================] - 4s 1ms/sample - loss: 0.1126 - fn: 1.0000 - fp: 9.0000 - tn: 2576.0000 - tp: 1034.0000 - precision: 0.9914 - recall: 0.9990 - val_loss: 0.1810 - val_fn: 22.0000 - val_fp: 21.0000 - val_tn: 1066.0000 - val_tp: 443.0000 - val_precision: 0.9547 - val_recall: 0.9527\n",
      "Epoch 105/150\n",
      "3620/3620 [==============================] - 4s 1ms/sample - loss: 0.1126 - fn: 1.0000 - fp: 9.0000 - tn: 2576.0000 - tp: 1034.0000 - precision: 0.9914 - recall: 0.9990 - val_loss: 0.1810 - val_fn: 22.0000 - val_fp: 21.0000 - val_tn: 1066.0000 - val_tp: 443.0000 - val_precision: 0.9547 - val_recall: 0.9527\n",
      "Epoch 106/150\n",
      "3620/3620 [==============================] - 5s 1ms/sample - loss: 0.1126 - fn: 1.0000 - fp: 9.0000 - tn: 2576.0000 - tp: 1034.0000 - precision: 0.9914 - recall: 0.9990 - val_loss: 0.1810 - val_fn: 22.0000 - val_fp: 21.0000 - val_tn: 1066.0000 - val_tp: 443.0000 - val_precision: 0.9547 - val_recall: 0.9527\n",
      "Epoch 107/150\n",
      "3620/3620 [==============================] - 4s 1ms/sample - loss: 0.1126 - fn: 1.0000 - fp: 9.0000 - tn: 2576.0000 - tp: 1034.0000 - precision: 0.9914 - recall: 0.9990 - val_loss: 0.1810 - val_fn: 22.0000 - val_fp: 21.0000 - val_tn: 1066.0000 - val_tp: 443.0000 - val_precision: 0.9547 - val_recall: 0.9527\n",
      "Epoch 108/150\n",
      "3620/3620 [==============================] - 4s 1ms/sample - loss: 0.1126 - fn: 1.0000 - fp: 9.0000 - tn: 2576.0000 - tp: 1034.0000 - precision: 0.9914 - recall: 0.9990 - val_loss: 0.1810 - val_fn: 22.0000 - val_fp: 21.0000 - val_tn: 1066.0000 - val_tp: 443.0000 - val_precision: 0.9547 - val_recall: 0.9527\n",
      "Epoch 109/150\n",
      "3620/3620 [==============================] - 4s 1ms/sample - loss: 0.1126 - fn: 1.0000 - fp: 9.0000 - tn: 2576.0000 - tp: 1034.0000 - precision: 0.9914 - recall: 0.9990 - val_loss: 0.1810 - val_fn: 22.0000 - val_fp: 21.0000 - val_tn: 1066.0000 - val_tp: 443.0000 - val_precision: 0.9547 - val_recall: 0.9527\n",
      "Epoch 110/150\n",
      "3620/3620 [==============================] - 5s 1ms/sample - loss: 0.1126 - fn: 1.0000 - fp: 9.0000 - tn: 2576.0000 - tp: 1034.0000 - precision: 0.9914 - recall: 0.9990 - val_loss: 0.1810 - val_fn: 22.0000 - val_fp: 21.0000 - val_tn: 1066.0000 - val_tp: 443.0000 - val_precision: 0.9547 - val_recall: 0.9527\n",
      "Epoch 111/150\n",
      "3620/3620 [==============================] - 4s 1ms/sample - loss: 0.1126 - fn: 1.0000 - fp: 9.0000 - tn: 2576.0000 - tp: 1034.0000 - precision: 0.9914 - recall: 0.9990 - val_loss: 0.1810 - val_fn: 22.0000 - val_fp: 21.0000 - val_tn: 1066.0000 - val_tp: 443.0000 - val_precision: 0.9547 - val_recall: 0.9527\n",
      "Epoch 112/150\n",
      "3620/3620 [==============================] - 4s 1ms/sample - loss: 0.1126 - fn: 1.0000 - fp: 9.0000 - tn: 2576.0000 - tp: 1034.0000 - precision: 0.9914 - recall: 0.9990 - val_loss: 0.1810 - val_fn: 22.0000 - val_fp: 21.0000 - val_tn: 1066.0000 - val_tp: 443.0000 - val_precision: 0.9547 - val_recall: 0.9527\n",
      "Epoch 113/150\n",
      "3620/3620 [==============================] - 4s 1ms/sample - loss: 0.1126 - fn: 1.0000 - fp: 9.0000 - tn: 2576.0000 - tp: 1034.0000 - precision: 0.9914 - recall: 0.9990 - val_loss: 0.1810 - val_fn: 22.0000 - val_fp: 21.0000 - val_tn: 1066.0000 - val_tp: 443.0000 - val_precision: 0.9547 - val_recall: 0.9527\n",
      "Epoch 114/150\n",
      "3620/3620 [==============================] - 5s 1ms/sample - loss: 0.1126 - fn: 1.0000 - fp: 9.0000 - tn: 2576.0000 - tp: 1034.0000 - precision: 0.9914 - recall: 0.9990 - val_loss: 0.1810 - val_fn: 22.0000 - val_fp: 21.0000 - val_tn: 1066.0000 - val_tp: 443.0000 - val_precision: 0.9547 - val_recall: 0.9527\n",
      "Epoch 115/150\n",
      "3620/3620 [==============================] - 5s 1ms/sample - loss: 0.1126 - fn: 1.0000 - fp: 9.0000 - tn: 2576.0000 - tp: 1034.0000 - precision: 0.9914 - recall: 0.9990 - val_loss: 0.1810 - val_fn: 22.0000 - val_fp: 21.0000 - val_tn: 1066.0000 - val_tp: 443.0000 - val_precision: 0.9547 - val_recall: 0.9527\n",
      "Epoch 116/150\n",
      "3620/3620 [==============================] - 5s 1ms/sample - loss: 0.1126 - fn: 1.0000 - fp: 9.0000 - tn: 2576.0000 - tp: 1034.0000 - precision: 0.9914 - recall: 0.9990 - val_loss: 0.1810 - val_fn: 22.0000 - val_fp: 21.0000 - val_tn: 1066.0000 - val_tp: 443.0000 - val_precision: 0.9547 - val_recall: 0.9527\n",
      "Epoch 117/150\n",
      "3620/3620 [==============================] - 5s 1ms/sample - loss: 0.1126 - fn: 1.0000 - fp: 9.0000 - tn: 2576.0000 - tp: 1034.0000 - precision: 0.9914 - recall: 0.9990 - val_loss: 0.1810 - val_fn: 22.0000 - val_fp: 21.0000 - val_tn: 1066.0000 - val_tp: 443.0000 - val_precision: 0.9547 - val_recall: 0.9527\n",
      "Epoch 118/150\n",
      "3620/3620 [==============================] - 5s 1ms/sample - loss: 0.1126 - fn: 1.0000 - fp: 9.0000 - tn: 2576.0000 - tp: 1034.0000 - precision: 0.9914 - recall: 0.9990 - val_loss: 0.1810 - val_fn: 22.0000 - val_fp: 21.0000 - val_tn: 1066.0000 - val_tp: 443.0000 - val_precision: 0.9547 - val_recall: 0.9527\n",
      "Epoch 119/150\n",
      "3620/3620 [==============================] - 5s 1ms/sample - loss: 0.1126 - fn: 1.0000 - fp: 9.0000 - tn: 2576.0000 - tp: 1034.0000 - precision: 0.9914 - recall: 0.9990 - val_loss: 0.1810 - val_fn: 22.0000 - val_fp: 21.0000 - val_tn: 1066.0000 - val_tp: 443.0000 - val_precision: 0.9547 - val_recall: 0.9527\n",
      "Epoch 120/150\n",
      "3620/3620 [==============================] - 5s 1ms/sample - loss: 0.1126 - fn: 1.0000 - fp: 9.0000 - tn: 2576.0000 - tp: 1034.0000 - precision: 0.9914 - recall: 0.9990 - val_loss: 0.1810 - val_fn: 22.0000 - val_fp: 21.0000 - val_tn: 1066.0000 - val_tp: 443.0000 - val_precision: 0.9547 - val_recall: 0.9527\n",
      "Epoch 121/150\n",
      "3620/3620 [==============================] - 5s 1ms/sample - loss: 0.1126 - fn: 1.0000 - fp: 9.0000 - tn: 2576.0000 - tp: 1034.0000 - precision: 0.9914 - recall: 0.9990 - val_loss: 0.1810 - val_fn: 22.0000 - val_fp: 21.0000 - val_tn: 1066.0000 - val_tp: 443.0000 - val_precision: 0.9547 - val_recall: 0.9527\n",
      "Epoch 122/150\n",
      "3620/3620 [==============================] - 5s 1ms/sample - loss: 0.1126 - fn: 1.0000 - fp: 9.0000 - tn: 2576.0000 - tp: 1034.0000 - precision: 0.9914 - recall: 0.9990 - val_loss: 0.1810 - val_fn: 22.0000 - val_fp: 21.0000 - val_tn: 1066.0000 - val_tp: 443.0000 - val_precision: 0.9547 - val_recall: 0.9527\n",
      "Epoch 123/150\n",
      "3620/3620 [==============================] - 4s 1ms/sample - loss: 0.1126 - fn: 1.0000 - fp: 9.0000 - tn: 2576.0000 - tp: 1034.0000 - precision: 0.9914 - recall: 0.9990 - val_loss: 0.1810 - val_fn: 22.0000 - val_fp: 21.0000 - val_tn: 1066.0000 - val_tp: 443.0000 - val_precision: 0.9547 - val_recall: 0.9527\n",
      "Epoch 124/150\n",
      "3620/3620 [==============================] - 5s 1ms/sample - loss: 0.1126 - fn: 1.0000 - fp: 9.0000 - tn: 2576.0000 - tp: 1034.0000 - precision: 0.9914 - recall: 0.9990 - val_loss: 0.1810 - val_fn: 22.0000 - val_fp: 21.0000 - val_tn: 1066.0000 - val_tp: 443.0000 - val_precision: 0.9547 - val_recall: 0.9527\n",
      "Epoch 125/150\n",
      "3620/3620 [==============================] - 5s 1ms/sample - loss: 0.1126 - fn: 1.0000 - fp: 9.0000 - tn: 2576.0000 - tp: 1034.0000 - precision: 0.9914 - recall: 0.9990 - val_loss: 0.1810 - val_fn: 22.0000 - val_fp: 21.0000 - val_tn: 1066.0000 - val_tp: 443.0000 - val_precision: 0.9547 - val_recall: 0.9527\n",
      "Epoch 126/150\n",
      "3620/3620 [==============================] - 4s 1ms/sample - loss: 0.1126 - fn: 1.0000 - fp: 9.0000 - tn: 2576.0000 - tp: 1034.0000 - precision: 0.9914 - recall: 0.9990 - val_loss: 0.1810 - val_fn: 22.0000 - val_fp: 21.0000 - val_tn: 1066.0000 - val_tp: 443.0000 - val_precision: 0.9547 - val_recall: 0.9527\n",
      "Epoch 127/150\n",
      "3620/3620 [==============================] - 4s 1ms/sample - loss: 0.1126 - fn: 1.0000 - fp: 9.0000 - tn: 2576.0000 - tp: 1034.0000 - precision: 0.9914 - recall: 0.9990 - val_loss: 0.1810 - val_fn: 22.0000 - val_fp: 21.0000 - val_tn: 1066.0000 - val_tp: 443.0000 - val_precision: 0.9547 - val_recall: 0.9527\n",
      "Epoch 128/150\n",
      "3620/3620 [==============================] - 5s 1ms/sample - loss: 0.1126 - fn: 1.0000 - fp: 9.0000 - tn: 2576.0000 - tp: 1034.0000 - precision: 0.9914 - recall: 0.9990 - val_loss: 0.1810 - val_fn: 22.0000 - val_fp: 21.0000 - val_tn: 1066.0000 - val_tp: 443.0000 - val_precision: 0.9547 - val_recall: 0.9527\n",
      "Epoch 129/150\n",
      "3620/3620 [==============================] - 4s 1ms/sample - loss: 0.1126 - fn: 1.0000 - fp: 9.0000 - tn: 2576.0000 - tp: 1034.0000 - precision: 0.9914 - recall: 0.9990 - val_loss: 0.1810 - val_fn: 22.0000 - val_fp: 21.0000 - val_tn: 1066.0000 - val_tp: 443.0000 - val_precision: 0.9547 - val_recall: 0.9527\n",
      "Epoch 130/150\n",
      "3620/3620 [==============================] - 4s 1ms/sample - loss: 0.1126 - fn: 1.0000 - fp: 9.0000 - tn: 2576.0000 - tp: 1034.0000 - precision: 0.9914 - recall: 0.9990 - val_loss: 0.1810 - val_fn: 22.0000 - val_fp: 21.0000 - val_tn: 1066.0000 - val_tp: 443.0000 - val_precision: 0.9547 - val_recall: 0.9527\n",
      "Epoch 131/150\n",
      "3620/3620 [==============================] - 5s 1ms/sample - loss: 0.1126 - fn: 1.0000 - fp: 9.0000 - tn: 2576.0000 - tp: 1034.0000 - precision: 0.9914 - recall: 0.9990 - val_loss: 0.1810 - val_fn: 22.0000 - val_fp: 21.0000 - val_tn: 1066.0000 - val_tp: 443.0000 - val_precision: 0.9547 - val_recall: 0.9527\n",
      "Epoch 132/150\n",
      "3620/3620 [==============================] - 4s 1ms/sample - loss: 0.1126 - fn: 1.0000 - fp: 9.0000 - tn: 2576.0000 - tp: 1034.0000 - precision: 0.9914 - recall: 0.9990 - val_loss: 0.1810 - val_fn: 22.0000 - val_fp: 21.0000 - val_tn: 1066.0000 - val_tp: 443.0000 - val_precision: 0.9547 - val_recall: 0.9527\n",
      "Epoch 133/150\n",
      "3620/3620 [==============================] - 5s 1ms/sample - loss: 0.1126 - fn: 1.0000 - fp: 9.0000 - tn: 2576.0000 - tp: 1034.0000 - precision: 0.9914 - recall: 0.9990 - val_loss: 0.1810 - val_fn: 22.0000 - val_fp: 21.0000 - val_tn: 1066.0000 - val_tp: 443.0000 - val_precision: 0.9547 - val_recall: 0.9527\n",
      "Epoch 134/150\n",
      "3620/3620 [==============================] - 5s 1ms/sample - loss: 0.1126 - fn: 1.0000 - fp: 9.0000 - tn: 2576.0000 - tp: 1034.0000 - precision: 0.9914 - recall: 0.9990 - val_loss: 0.1810 - val_fn: 22.0000 - val_fp: 21.0000 - val_tn: 1066.0000 - val_tp: 443.0000 - val_precision: 0.9547 - val_recall: 0.9527\n",
      "Epoch 135/150\n",
      "3620/3620 [==============================] - 5s 1ms/sample - loss: 0.1126 - fn: 1.0000 - fp: 9.0000 - tn: 2576.0000 - tp: 1034.0000 - precision: 0.9914 - recall: 0.9990 - val_loss: 0.1810 - val_fn: 22.0000 - val_fp: 21.0000 - val_tn: 1066.0000 - val_tp: 443.0000 - val_precision: 0.9547 - val_recall: 0.9527\n",
      "Epoch 136/150\n",
      "3620/3620 [==============================] - 5s 1ms/sample - loss: 0.1126 - fn: 1.0000 - fp: 9.0000 - tn: 2576.0000 - tp: 1034.0000 - precision: 0.9914 - recall: 0.9990 - val_loss: 0.1810 - val_fn: 22.0000 - val_fp: 21.0000 - val_tn: 1066.0000 - val_tp: 443.0000 - val_precision: 0.9547 - val_recall: 0.9527\n",
      "Epoch 137/150\n",
      "3620/3620 [==============================] - 4s 1ms/sample - loss: 0.1126 - fn: 1.0000 - fp: 9.0000 - tn: 2576.0000 - tp: 1034.0000 - precision: 0.9914 - recall: 0.9990 - val_loss: 0.1810 - val_fn: 22.0000 - val_fp: 21.0000 - val_tn: 1066.0000 - val_tp: 443.0000 - val_precision: 0.9547 - val_recall: 0.9527\n",
      "Epoch 138/150\n",
      "3620/3620 [==============================] - 5s 1ms/sample - loss: 0.1126 - fn: 1.0000 - fp: 9.0000 - tn: 2576.0000 - tp: 1034.0000 - precision: 0.9914 - recall: 0.9990 - val_loss: 0.1810 - val_fn: 22.0000 - val_fp: 21.0000 - val_tn: 1066.0000 - val_tp: 443.0000 - val_precision: 0.9547 - val_recall: 0.9527\n",
      "Epoch 139/150\n",
      "3620/3620 [==============================] - 5s 1ms/sample - loss: 0.1126 - fn: 1.0000 - fp: 9.0000 - tn: 2576.0000 - tp: 1034.0000 - precision: 0.9914 - recall: 0.9990 - val_loss: 0.1810 - val_fn: 22.0000 - val_fp: 21.0000 - val_tn: 1066.0000 - val_tp: 443.0000 - val_precision: 0.9547 - val_recall: 0.9527\n",
      "Epoch 140/150\n",
      "3620/3620 [==============================] - 4s 1ms/sample - loss: 0.1126 - fn: 1.0000 - fp: 9.0000 - tn: 2576.0000 - tp: 1034.0000 - precision: 0.9914 - recall: 0.9990 - val_loss: 0.1810 - val_fn: 22.0000 - val_fp: 21.0000 - val_tn: 1066.0000 - val_tp: 443.0000 - val_precision: 0.9547 - val_recall: 0.9527\n",
      "Epoch 141/150\n",
      "3620/3620 [==============================] - 5s 1ms/sample - loss: 0.1126 - fn: 1.0000 - fp: 9.0000 - tn: 2576.0000 - tp: 1034.0000 - precision: 0.9914 - recall: 0.9990 - val_loss: 0.1810 - val_fn: 22.0000 - val_fp: 21.0000 - val_tn: 1066.0000 - val_tp: 443.0000 - val_precision: 0.9547 - val_recall: 0.9527\n",
      "Epoch 142/150\n",
      "3620/3620 [==============================] - 5s 1ms/sample - loss: 0.1126 - fn: 1.0000 - fp: 9.0000 - tn: 2576.0000 - tp: 1034.0000 - precision: 0.9914 - recall: 0.9990 - val_loss: 0.1810 - val_fn: 22.0000 - val_fp: 21.0000 - val_tn: 1066.0000 - val_tp: 443.0000 - val_precision: 0.9547 - val_recall: 0.9527\n",
      "Epoch 143/150\n",
      "3620/3620 [==============================] - 5s 1ms/sample - loss: 0.1126 - fn: 1.0000 - fp: 9.0000 - tn: 2576.0000 - tp: 1034.0000 - precision: 0.9914 - recall: 0.9990 - val_loss: 0.1810 - val_fn: 22.0000 - val_fp: 21.0000 - val_tn: 1066.0000 - val_tp: 443.0000 - val_precision: 0.9547 - val_recall: 0.9527\n",
      "Epoch 144/150\n",
      "3620/3620 [==============================] - 5s 1ms/sample - loss: 0.1126 - fn: 1.0000 - fp: 9.0000 - tn: 2576.0000 - tp: 1034.0000 - precision: 0.9914 - recall: 0.9990 - val_loss: 0.1810 - val_fn: 22.0000 - val_fp: 21.0000 - val_tn: 1066.0000 - val_tp: 443.0000 - val_precision: 0.9547 - val_recall: 0.9527\n",
      "Epoch 145/150\n",
      "3620/3620 [==============================] - 5s 1ms/sample - loss: 0.1126 - fn: 1.0000 - fp: 9.0000 - tn: 2576.0000 - tp: 1034.0000 - precision: 0.9914 - recall: 0.9990 - val_loss: 0.1810 - val_fn: 22.0000 - val_fp: 21.0000 - val_tn: 1066.0000 - val_tp: 443.0000 - val_precision: 0.9547 - val_recall: 0.9527\n",
      "Epoch 146/150\n",
      "3620/3620 [==============================] - 4s 1ms/sample - loss: 0.1126 - fn: 1.0000 - fp: 9.0000 - tn: 2576.0000 - tp: 1034.0000 - precision: 0.9914 - recall: 0.9990 - val_loss: 0.1810 - val_fn: 22.0000 - val_fp: 21.0000 - val_tn: 1066.0000 - val_tp: 443.0000 - val_precision: 0.9547 - val_recall: 0.9527\n",
      "Epoch 147/150\n",
      "3620/3620 [==============================] - 4s 1ms/sample - loss: 0.1126 - fn: 1.0000 - fp: 9.0000 - tn: 2576.0000 - tp: 1034.0000 - precision: 0.9914 - recall: 0.9990 - val_loss: 0.1810 - val_fn: 22.0000 - val_fp: 21.0000 - val_tn: 1066.0000 - val_tp: 443.0000 - val_precision: 0.9547 - val_recall: 0.9527\n",
      "Epoch 148/150\n",
      "3620/3620 [==============================] - 4s 1ms/sample - loss: 0.1126 - fn: 1.0000 - fp: 9.0000 - tn: 2576.0000 - tp: 1034.0000 - precision: 0.9914 - recall: 0.9990 - val_loss: 0.1810 - val_fn: 22.0000 - val_fp: 21.0000 - val_tn: 1066.0000 - val_tp: 443.0000 - val_precision: 0.9547 - val_recall: 0.9527\n",
      "Epoch 149/150\n",
      "3620/3620 [==============================] - 4s 1ms/sample - loss: 0.1126 - fn: 1.0000 - fp: 9.0000 - tn: 2576.0000 - tp: 1034.0000 - precision: 0.9914 - recall: 0.9990 - val_loss: 0.1810 - val_fn: 22.0000 - val_fp: 21.0000 - val_tn: 1066.0000 - val_tp: 443.0000 - val_precision: 0.9547 - val_recall: 0.9527\n",
      "Epoch 150/150\n",
      "3620/3620 [==============================] - 4s 1ms/sample - loss: 0.1126 - fn: 1.0000 - fp: 9.0000 - tn: 2576.0000 - tp: 1034.0000 - precision: 0.9914 - recall: 0.9990 - val_loss: 0.1810 - val_fn: 22.0000 - val_fp: 21.0000 - val_tn: 1066.0000 - val_tp: 443.0000 - val_precision: 0.9547 - val_recall: 0.9527\n"
     ]
    }
   ],
   "source": [
    "metrics = [\n",
    "    keras.metrics.FalseNegatives(name=\"fn\"),\n",
    "    keras.metrics.FalsePositives(name=\"fp\"),\n",
    "    keras.metrics.TrueNegatives(name=\"tn\"),\n",
    "    keras.metrics.TruePositives(name=\"tp\"),\n",
    "    keras.metrics.Precision(name=\"precision\"),\n",
    "    keras.metrics.Recall(name=\"recall\"),\n",
    "]\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    1e-1,\n",
    "    decay_steps=100,\n",
    "    decay_rate=0.9,\n",
    "    staircase=True)\n",
    "model.compile(optimizer=keras.optimizers.SGD(learning_rate=lr_schedule),loss='binary_crossentropy',metrics=metrics)\n",
    "history=model.fit(X, label,validation_split=0.3,\n",
    "           epochs=150)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
